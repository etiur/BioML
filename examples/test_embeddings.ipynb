{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel,  AutoModelForSequenceClassification\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# https://huggingface.co/blog/AmelieSchreiber/esmbind\n",
    "# the minimum for the ESM2 is 650M if we want better performance than ESM1b with 650M as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.arange(40, dtype=torch.float32).view(10, 4), torch.tensor([i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(40).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[12., 13., 14., 15.]],\n",
      "\n",
      "        [[28., 29., 30., 31.]],\n",
      "\n",
      "        [[20., 21., 22., 23.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[  7.9515,   8.6100,   9.2686],\n",
      "         [ -5.7440,  -6.2499,  -6.7559],\n",
      "         [ -2.4015,  -2.5816,  -2.7617],\n",
      "         [-12.2291, -13.2001, -14.1711],\n",
      "         [ 10.4888,  11.3591,  12.2294],\n",
      "         [  3.9718,   4.3172,   4.6625],\n",
      "         [  1.2479,   1.3680,   1.4881],\n",
      "         [ -0.7694,  -0.8526,  -0.9357],\n",
      "         [-12.2041, -13.1510, -14.0978],\n",
      "         [ -2.9194,  -3.1050,  -3.2906]],\n",
      "\n",
      "        [[ 18.4879,  19.1464,  19.8049],\n",
      "         [-13.8394, -14.3453, -14.8513],\n",
      "         [ -5.2831,  -5.4632,  -5.6433],\n",
      "         [-27.7649, -28.7359, -29.7069],\n",
      "         [ 24.4138,  25.2841,  26.1544],\n",
      "         [  9.4968,   9.8421,  10.1874],\n",
      "         [  3.1696,   3.2897,   3.4098],\n",
      "         [ -2.0995,  -2.1826,  -2.2658],\n",
      "         [-27.3533, -28.3001, -29.2469],\n",
      "         [ -5.8897,  -6.0753,  -6.2610]],\n",
      "\n",
      "        [[ 13.2197,  13.8782,  14.5367],\n",
      "         [ -9.7917, -10.2976, -10.8036],\n",
      "         [ -3.8423,  -4.0224,  -4.2025],\n",
      "         [-19.9970, -20.9680, -21.9390],\n",
      "         [ 17.4513,  18.3216,  19.1919],\n",
      "         [  6.7343,   7.0796,   7.4249],\n",
      "         [  2.2088,   2.3289,   2.4490],\n",
      "         [ -1.4345,  -1.5176,  -1.6007],\n",
      "         [-19.7787, -20.7255, -21.6724],\n",
      "         [ -4.4045,  -4.5902,  -4.7758]],\n",
      "\n",
      "        [[  5.3174,   5.9760,   6.6345],\n",
      "         [ -3.7201,  -4.2261,  -4.7320],\n",
      "         [ -1.6810,  -1.8611,  -2.0412],\n",
      "         [ -8.3452,  -9.3162, -10.2872],\n",
      "         [  7.0076,   7.8779,   8.7482],\n",
      "         [  2.5906,   2.9359,   3.2812],\n",
      "         [  0.7675,   0.8876,   1.0077],\n",
      "         [ -0.4369,  -0.5201,  -0.6032],\n",
      "         [ -8.4169,  -9.3637, -10.3105],\n",
      "         [ -2.1768,  -2.3624,  -2.5481]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[32., 33., 34., 35.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[24., 25., 26., 27.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[  0.0493,   0.7078,   1.3663],\n",
      "         [  0.3276,  -0.1784,  -0.6843],\n",
      "         [ -0.2402,  -0.4203,  -0.6004],\n",
      "         [ -0.5773,  -1.5483,  -2.5193],\n",
      "         [  0.0451,   0.9154,   1.7857],\n",
      "         [ -0.1719,   0.1734,   0.5188],\n",
      "         [ -0.1933,  -0.0732,   0.0469],\n",
      "         [  0.2281,   0.1450,   0.0619],\n",
      "         [ -0.8423,  -1.7891,  -2.7359],\n",
      "         [ -0.6916,  -0.8772,  -1.0629]],\n",
      "\n",
      "        [[ 21.1219,  21.7805,  22.4390],\n",
      "         [-15.8632, -16.3692, -16.8751],\n",
      "         [ -6.0035,  -6.1837,  -6.3638],\n",
      "         [-31.6488, -32.6198, -33.5908],\n",
      "         [ 27.8951,  28.7654,  29.6357],\n",
      "         [ 10.8780,  11.2233,  11.5686],\n",
      "         [  3.6500,   3.7701,   3.8902],\n",
      "         [ -2.4320,  -2.5152,  -2.5983],\n",
      "         [-31.1406, -32.0874, -33.0342],\n",
      "         [ -6.6323,  -6.8179,  -7.0036]],\n",
      "\n",
      "        [[  2.6834,   3.3419,   4.0004],\n",
      "         [ -1.6963,  -2.2022,  -2.7082],\n",
      "         [ -0.9606,  -1.1407,  -1.3208],\n",
      "         [ -4.4613,  -5.4322,  -6.4032],\n",
      "         [  3.5263,   4.3966,   5.2669],\n",
      "         [  1.2094,   1.5547,   1.9000],\n",
      "         [  0.2871,   0.4072,   0.5273],\n",
      "         [ -0.1044,  -0.1875,  -0.2707],\n",
      "         [ -4.6296,  -5.5764,  -6.5232],\n",
      "         [ -1.4342,  -1.6198,  -1.8055]],\n",
      "\n",
      "        [[ 15.8538,  16.5123,  17.1708],\n",
      "         [-11.8155, -12.3215, -12.8274],\n",
      "         [ -4.5627,  -4.7428,  -4.9229],\n",
      "         [-23.8810, -24.8519, -25.8229],\n",
      "         [ 20.9326,  21.8029,  22.6732],\n",
      "         [  8.1155,   8.4609,   8.8062],\n",
      "         [  2.6892,   2.8093,   2.9294],\n",
      "         [ -1.7670,  -1.8501,  -1.9333],\n",
      "         [-23.5660, -24.5128, -25.4597],\n",
      "         [ -5.1471,  -5.3328,  -5.5184]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([2, 1, 4])\n",
      "tensor([[[36., 37., 38., 39.]],\n",
      "\n",
      "        [[16., 17., 18., 19.]]])\n",
      "torch.Size([2, 10, 3])\n",
      "tensor([[[ 23.7560,  24.4145,  25.0731],\n",
      "         [-17.8871, -18.3930, -18.8990],\n",
      "         [ -6.7240,  -6.9041,  -7.0842],\n",
      "         [-35.5328, -36.5038, -37.4748],\n",
      "         [ 31.3763,  32.2466,  33.1169],\n",
      "         [ 12.2593,  12.6046,  12.9499],\n",
      "         [  4.1304,   4.2505,   4.3707],\n",
      "         [ -2.7645,  -2.8477,  -2.9308],\n",
      "         [-34.9279, -35.8747, -36.8215],\n",
      "         [ -7.3749,  -7.5605,  -7.7462]],\n",
      "\n",
      "        [[ 10.5856,  11.2441,  11.9026],\n",
      "         [ -7.7678,  -8.2738,  -8.7797],\n",
      "         [ -3.1219,  -3.3020,  -3.4821],\n",
      "         [-16.1131, -17.0841, -18.0550],\n",
      "         [ 13.9701,  14.8404,  15.7107],\n",
      "         [  5.3531,   5.6984,   6.0437],\n",
      "         [  1.7284,   1.8485,   1.9686],\n",
      "         [ -1.1020,  -1.1851,  -1.2682],\n",
      "         [-15.9914, -16.9383, -17.8851],\n",
      "         [ -3.6619,  -3.8476,  -4.0332]]], grad_fn=<ConvolutionBackward0>)\n",
      "Epoch 1\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[12., 13., 14., 15.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[28., 29., 30., 31.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[  2.6834,   3.3419,   4.0004],\n",
      "         [ -1.6963,  -2.2022,  -2.7082],\n",
      "         [ -0.9606,  -1.1407,  -1.3208],\n",
      "         [ -4.4613,  -5.4322,  -6.4032],\n",
      "         [  3.5263,   4.3966,   5.2669],\n",
      "         [  1.2094,   1.5547,   1.9000],\n",
      "         [  0.2871,   0.4072,   0.5273],\n",
      "         [ -0.1044,  -0.1875,  -0.2707],\n",
      "         [ -4.6296,  -5.5764,  -6.5232],\n",
      "         [ -1.4342,  -1.6198,  -1.8055]],\n",
      "\n",
      "        [[  7.9515,   8.6100,   9.2686],\n",
      "         [ -5.7440,  -6.2499,  -6.7559],\n",
      "         [ -2.4015,  -2.5816,  -2.7617],\n",
      "         [-12.2291, -13.2001, -14.1711],\n",
      "         [ 10.4888,  11.3591,  12.2294],\n",
      "         [  3.9718,   4.3172,   4.6625],\n",
      "         [  1.2479,   1.3680,   1.4881],\n",
      "         [ -0.7694,  -0.8526,  -0.9357],\n",
      "         [-12.2041, -13.1510, -14.0978],\n",
      "         [ -2.9194,  -3.1050,  -3.2906]],\n",
      "\n",
      "        [[  5.3174,   5.9760,   6.6345],\n",
      "         [ -3.7201,  -4.2261,  -4.7320],\n",
      "         [ -1.6810,  -1.8611,  -2.0412],\n",
      "         [ -8.3452,  -9.3162, -10.2872],\n",
      "         [  7.0076,   7.8779,   8.7482],\n",
      "         [  2.5906,   2.9359,   3.2812],\n",
      "         [  0.7675,   0.8876,   1.0077],\n",
      "         [ -0.4369,  -0.5201,  -0.6032],\n",
      "         [ -8.4169,  -9.3637, -10.3105],\n",
      "         [ -2.1768,  -2.3624,  -2.5481]],\n",
      "\n",
      "        [[ 18.4879,  19.1464,  19.8049],\n",
      "         [-13.8394, -14.3453, -14.8513],\n",
      "         [ -5.2831,  -5.4632,  -5.6433],\n",
      "         [-27.7649, -28.7359, -29.7069],\n",
      "         [ 24.4138,  25.2841,  26.1544],\n",
      "         [  9.4968,   9.8421,  10.1874],\n",
      "         [  3.1696,   3.2897,   3.4098],\n",
      "         [ -2.0995,  -2.1826,  -2.2658],\n",
      "         [-27.3533, -28.3001, -29.2469],\n",
      "         [ -5.8897,  -6.0753,  -6.2610]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[20., 21., 22., 23.]],\n",
      "\n",
      "        [[36., 37., 38., 39.]],\n",
      "\n",
      "        [[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[24., 25., 26., 27.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[ 13.2197,  13.8782,  14.5367],\n",
      "         [ -9.7917, -10.2976, -10.8036],\n",
      "         [ -3.8423,  -4.0224,  -4.2025],\n",
      "         [-19.9970, -20.9680, -21.9390],\n",
      "         [ 17.4513,  18.3216,  19.1919],\n",
      "         [  6.7343,   7.0796,   7.4249],\n",
      "         [  2.2088,   2.3289,   2.4490],\n",
      "         [ -1.4345,  -1.5176,  -1.6007],\n",
      "         [-19.7787, -20.7255, -21.6724],\n",
      "         [ -4.4045,  -4.5902,  -4.7758]],\n",
      "\n",
      "        [[ 23.7560,  24.4145,  25.0731],\n",
      "         [-17.8871, -18.3930, -18.8990],\n",
      "         [ -6.7240,  -6.9041,  -7.0842],\n",
      "         [-35.5328, -36.5038, -37.4748],\n",
      "         [ 31.3763,  32.2466,  33.1169],\n",
      "         [ 12.2593,  12.6046,  12.9499],\n",
      "         [  4.1304,   4.2505,   4.3707],\n",
      "         [ -2.7645,  -2.8477,  -2.9308],\n",
      "         [-34.9279, -35.8747, -36.8215],\n",
      "         [ -7.3749,  -7.5605,  -7.7462]],\n",
      "\n",
      "        [[  0.0493,   0.7078,   1.3663],\n",
      "         [  0.3276,  -0.1784,  -0.6843],\n",
      "         [ -0.2402,  -0.4203,  -0.6004],\n",
      "         [ -0.5773,  -1.5483,  -2.5193],\n",
      "         [  0.0451,   0.9154,   1.7857],\n",
      "         [ -0.1719,   0.1734,   0.5188],\n",
      "         [ -0.1933,  -0.0732,   0.0469],\n",
      "         [  0.2281,   0.1450,   0.0619],\n",
      "         [ -0.8423,  -1.7891,  -2.7359],\n",
      "         [ -0.6916,  -0.8772,  -1.0629]],\n",
      "\n",
      "        [[ 15.8538,  16.5123,  17.1708],\n",
      "         [-11.8155, -12.3215, -12.8274],\n",
      "         [ -4.5627,  -4.7428,  -4.9229],\n",
      "         [-23.8810, -24.8519, -25.8229],\n",
      "         [ 20.9326,  21.8029,  22.6732],\n",
      "         [  8.1155,   8.4609,   8.8062],\n",
      "         [  2.6892,   2.8093,   2.9294],\n",
      "         [ -1.7670,  -1.8501,  -1.9333],\n",
      "         [-23.5660, -24.5128, -25.4597],\n",
      "         [ -5.1471,  -5.3328,  -5.5184]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([2, 1, 4])\n",
      "tensor([[[16., 17., 18., 19.]],\n",
      "\n",
      "        [[32., 33., 34., 35.]]])\n",
      "torch.Size([2, 10, 3])\n",
      "tensor([[[ 10.5856,  11.2441,  11.9026],\n",
      "         [ -7.7678,  -8.2738,  -8.7797],\n",
      "         [ -3.1219,  -3.3020,  -3.4821],\n",
      "         [-16.1131, -17.0841, -18.0550],\n",
      "         [ 13.9701,  14.8404,  15.7107],\n",
      "         [  5.3531,   5.6984,   6.0437],\n",
      "         [  1.7284,   1.8485,   1.9686],\n",
      "         [ -1.1020,  -1.1851,  -1.2682],\n",
      "         [-15.9914, -16.9383, -17.8851],\n",
      "         [ -3.6619,  -3.8476,  -4.0332]],\n",
      "\n",
      "        [[ 21.1219,  21.7805,  22.4390],\n",
      "         [-15.8632, -16.3692, -16.8751],\n",
      "         [ -6.0035,  -6.1837,  -6.3638],\n",
      "         [-31.6488, -32.6198, -33.5908],\n",
      "         [ 27.8951,  28.7654,  29.6357],\n",
      "         [ 10.8780,  11.2233,  11.5686],\n",
      "         [  3.6500,   3.7701,   3.8902],\n",
      "         [ -2.4320,  -2.5152,  -2.5983],\n",
      "         [-31.1406, -32.0874, -33.0342],\n",
      "         [ -6.6323,  -6.8179,  -7.0036]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = nn.Conv1d(1, 10, 2)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "dl = DataLoader(dataset, batch_size=4, worker_init_fn=seed_worker, generator=g, shuffle=True, num_workers=2)\n",
    "for i in range(2):\n",
    "    print(\"Epoch\", i)\n",
    "    for batch, label in dl:\n",
    "       print(batch.unsqueeze(1).shape)\n",
    "       print(batch.unsqueeze(1))\n",
    "       o = a(batch.unsqueeze(1))\n",
    "       print(o.shape)\n",
    "       print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[22., 23.]],\n",
       "\n",
       "        [[ 8.,  9.]],\n",
       "\n",
       "        [[34., 35.]],\n",
       "\n",
       "        [[12., 13.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/whole_sequence.fasta', 'r') as f:\n",
    "    seqs = list(SeqIO.parse(f, 'fasta'))\n",
    "seq = [str(s.seq) for s in seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "tok = tokenizer(seq[:2], padding=True, truncation=True, return_tensors=\"pt\", is_split_into_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, output_hidden_states=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "n = AutoModelForSequenceClassification.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = n(**tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([343, 320])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.hidden_states[-1].mean(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 343, 320)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(output.hidden_states[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = torch.nn.Linear(320, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mattention_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m attention_weights\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "attention_scores = attention_weights(output.hidden_states[-1])\n",
    "attention_weights = torch.softmax(attention_scores, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 343, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 109760])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp = output.hidden_states[-1].reshape(output.hidden_states[-1].shape[0], -1)\n",
    "_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1419,  0.5839, -0.0722,  ...,  0.4682, -0.6849, -0.3094],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, -107712)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0, 2048 - _temp.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.nn.functional.pad(_temp, (0, 2048 - _temp.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1419,  0.5839, -0.0722,  0.3390, -0.1853, -0.0982, -0.9235,  0.1019,\n",
       "        -0.4527, -0.6959], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109670"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(o[0].detach().numpy()).intersection(_temp[0].detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(output.hidden_states[-1][0][0].detach().numpy()).intersection(_temp[0][:100].detach().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioml_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
