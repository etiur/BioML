{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# https://huggingface.co/blog/AmelieSchreiber/esmbind\n",
    "# the minimum for the ESM2 is 650M if we want better performance than ESM1b with 650M as well.\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "import torch.nn.functional as F\n",
    "import bitsandbytes as bnb\n",
    "from bitsandbytes.nn import Linear8bitLt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.arange(40, dtype=torch.float32).view(10, 4), torch.tensor([i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(40).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[12., 13., 14., 15.]],\n",
      "\n",
      "        [[28., 29., 30., 31.]],\n",
      "\n",
      "        [[20., 21., 22., 23.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[ -4.5959,  -4.9393,  -5.2827],\n",
      "         [  8.7039,   9.3886,  10.0732],\n",
      "         [ -0.8663,  -0.8556,  -0.8448],\n",
      "         [  6.3920,   6.9061,   7.4203],\n",
      "         [  0.2911,   0.3711,   0.4510],\n",
      "         [ -1.7599,  -1.8867,  -2.0135],\n",
      "         [  2.6198,   2.8765,   3.1331],\n",
      "         [  5.5991,   6.0079,   6.4167],\n",
      "         [ -1.3713,  -1.3925,  -1.4138],\n",
      "         [ -5.1378,  -5.5518,  -5.9657]],\n",
      "\n",
      "        [[-10.0898, -10.4332, -10.7766],\n",
      "         [ 19.6582,  20.3429,  21.0275],\n",
      "         [ -0.6943,  -0.6836,  -0.6728],\n",
      "         [ 14.6182,  15.1323,  15.6464],\n",
      "         [  1.5701,   1.6500,   1.7300],\n",
      "         [ -3.7889,  -3.9157,  -4.0425],\n",
      "         [  6.7264,   6.9831,   7.2398],\n",
      "         [ 12.1402,  12.5490,  12.9578],\n",
      "         [ -1.7114,  -1.7326,  -1.7539],\n",
      "         [-11.7614, -12.1754, -12.5894]],\n",
      "\n",
      "        [[ -7.3429,  -7.6863,  -8.0296],\n",
      "         [ 14.1811,  14.8657,  15.5504],\n",
      "         [ -0.7803,  -0.7696,  -0.7588],\n",
      "         [ 10.5051,  11.0192,  11.5334],\n",
      "         [  0.9306,   1.0106,   1.0905],\n",
      "         [ -2.7744,  -2.9012,  -3.0280],\n",
      "         [  4.6731,   4.9298,   5.1865],\n",
      "         [  8.8696,   9.2785,   9.6873],\n",
      "         [ -1.5413,  -1.5626,  -1.5838],\n",
      "         [ -8.4496,  -8.8636,  -9.2776]],\n",
      "\n",
      "        [[ -3.2225,  -3.5658,  -3.9092],\n",
      "         [  5.9654,   6.6500,   7.3347],\n",
      "         [ -0.9093,  -0.8986,  -0.8878],\n",
      "         [  4.3355,   4.8496,   5.3637],\n",
      "         [ -0.0286,   0.0513,   0.1313],\n",
      "         [ -1.2526,  -1.3794,  -1.5063],\n",
      "         [  1.5932,   1.8498,   2.1065],\n",
      "         [  3.9638,   4.3726,   4.7815],\n",
      "         [ -1.2863,  -1.3075,  -1.3288],\n",
      "         [ -3.4819,  -3.8959,  -4.3098]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[32., 33., 34., 35.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[24., 25., 26., 27.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[ -0.4755,  -0.8189,  -1.1623],\n",
      "         [  0.4882,   1.1729,   1.8575],\n",
      "         [ -0.9953,  -0.9846,  -0.9738],\n",
      "         [  0.2224,   0.7365,   1.2507],\n",
      "         [ -0.6681,  -0.5882,  -0.5082],\n",
      "         [ -0.2381,  -0.3649,  -0.4917],\n",
      "         [ -0.4602,  -0.2035,   0.0532],\n",
      "         [  0.6933,   1.1021,   1.5109],\n",
      "         [ -1.1162,  -1.1375,  -1.1587],\n",
      "         [ -0.1701,  -0.5840,  -0.9980]],\n",
      "\n",
      "        [[-11.4633, -11.8067, -12.1500],\n",
      "         [ 22.3968,  23.0814,  23.7661],\n",
      "         [ -0.6513,  -0.6406,  -0.6298],\n",
      "         [ 16.6747,  17.1888,  17.7030],\n",
      "         [  1.8899,   1.9698,   2.0497],\n",
      "         [ -4.2961,  -4.4230,  -4.5498],\n",
      "         [  7.7531,   8.0098,   8.2664],\n",
      "         [ 13.7755,  14.1843,  14.5931],\n",
      "         [ -1.7964,  -1.8176,  -1.8389],\n",
      "         [-13.4173, -13.8313, -14.2453]],\n",
      "\n",
      "        [[ -1.8490,  -2.1924,  -2.5357],\n",
      "         [  3.2268,   3.9114,   4.5961],\n",
      "         [ -0.9523,  -0.9416,  -0.9308],\n",
      "         [  2.2789,   2.7931,   3.3072],\n",
      "         [ -0.3483,  -0.2684,  -0.1885],\n",
      "         [ -0.7454,  -0.8722,  -0.9990],\n",
      "         [  0.5665,   0.8232,   1.0798],\n",
      "         [  2.3286,   2.7374,   3.1462],\n",
      "         [ -1.2012,  -1.2225,  -1.2438],\n",
      "         [ -1.8260,  -2.2400,  -2.6539]],\n",
      "\n",
      "        [[ -8.7164,  -9.0597,  -9.4031],\n",
      "         [ 16.9197,  17.6043,  18.2889],\n",
      "         [ -0.7373,  -0.7266,  -0.7158],\n",
      "         [ 12.5616,  13.0758,  13.5899],\n",
      "         [  1.2504,   1.3303,   1.4102],\n",
      "         [ -3.2816,  -3.4085,  -3.5353],\n",
      "         [  5.6998,   5.9565,   6.2131],\n",
      "         [ 10.5049,  10.9137,  11.3225],\n",
      "         [ -1.6263,  -1.6476,  -1.6688],\n",
      "         [-10.1055, -10.5195, -10.9335]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([2, 1, 4])\n",
      "tensor([[[36., 37., 38., 39.]],\n",
      "\n",
      "        [[16., 17., 18., 19.]]])\n",
      "torch.Size([2, 10, 3])\n",
      "tensor([[[-12.8368, -13.1801, -13.5235],\n",
      "         [ 25.1354,  25.8200,  26.5047],\n",
      "         [ -0.6083,  -0.5976,  -0.5868],\n",
      "         [ 18.7313,  19.2454,  19.7595],\n",
      "         [  2.2096,   2.2895,   2.3695],\n",
      "         [ -4.8034,  -4.9302,  -5.0570],\n",
      "         [  8.7798,   9.0364,   9.2931],\n",
      "         [ 15.4107,  15.8195,  16.2284],\n",
      "         [ -1.8814,  -1.9026,  -1.9239],\n",
      "         [-15.0732, -15.4872, -15.9012]],\n",
      "\n",
      "        [[ -5.9694,  -6.3128,  -6.6562],\n",
      "         [ 11.4425,  12.1272,  12.8118],\n",
      "         [ -0.8233,  -0.8126,  -0.8018],\n",
      "         [  8.4486,   8.9627,   9.4768],\n",
      "         [  0.6109,   0.6908,   0.7708],\n",
      "         [ -2.2671,  -2.3939,  -2.5208],\n",
      "         [  3.6465,   3.9031,   4.1598],\n",
      "         [  7.2344,   7.6432,   8.0520],\n",
      "         [ -1.4563,  -1.4776,  -1.4988],\n",
      "         [ -6.7937,  -7.2077,  -7.6217]]], grad_fn=<ConvolutionBackward0>)\n",
      "Epoch 1\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[12., 13., 14., 15.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[28., 29., 30., 31.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[ -1.8490,  -2.1924,  -2.5357],\n",
      "         [  3.2268,   3.9114,   4.5961],\n",
      "         [ -0.9523,  -0.9416,  -0.9308],\n",
      "         [  2.2789,   2.7931,   3.3072],\n",
      "         [ -0.3483,  -0.2684,  -0.1885],\n",
      "         [ -0.7454,  -0.8722,  -0.9990],\n",
      "         [  0.5665,   0.8232,   1.0798],\n",
      "         [  2.3286,   2.7374,   3.1462],\n",
      "         [ -1.2012,  -1.2225,  -1.2438],\n",
      "         [ -1.8260,  -2.2400,  -2.6539]],\n",
      "\n",
      "        [[ -4.5959,  -4.9393,  -5.2827],\n",
      "         [  8.7039,   9.3886,  10.0732],\n",
      "         [ -0.8663,  -0.8556,  -0.8448],\n",
      "         [  6.3920,   6.9061,   7.4203],\n",
      "         [  0.2911,   0.3711,   0.4510],\n",
      "         [ -1.7599,  -1.8867,  -2.0135],\n",
      "         [  2.6198,   2.8765,   3.1331],\n",
      "         [  5.5991,   6.0079,   6.4167],\n",
      "         [ -1.3713,  -1.3925,  -1.4138],\n",
      "         [ -5.1378,  -5.5518,  -5.9657]],\n",
      "\n",
      "        [[ -3.2225,  -3.5658,  -3.9092],\n",
      "         [  5.9654,   6.6500,   7.3347],\n",
      "         [ -0.9093,  -0.8986,  -0.8878],\n",
      "         [  4.3355,   4.8496,   5.3637],\n",
      "         [ -0.0286,   0.0513,   0.1313],\n",
      "         [ -1.2526,  -1.3794,  -1.5063],\n",
      "         [  1.5932,   1.8498,   2.1065],\n",
      "         [  3.9638,   4.3726,   4.7815],\n",
      "         [ -1.2863,  -1.3075,  -1.3288],\n",
      "         [ -3.4819,  -3.8959,  -4.3098]],\n",
      "\n",
      "        [[-10.0898, -10.4332, -10.7766],\n",
      "         [ 19.6582,  20.3429,  21.0275],\n",
      "         [ -0.6943,  -0.6836,  -0.6728],\n",
      "         [ 14.6182,  15.1323,  15.6464],\n",
      "         [  1.5701,   1.6500,   1.7300],\n",
      "         [ -3.7889,  -3.9157,  -4.0425],\n",
      "         [  6.7264,   6.9831,   7.2398],\n",
      "         [ 12.1402,  12.5490,  12.9578],\n",
      "         [ -1.7114,  -1.7326,  -1.7539],\n",
      "         [-11.7614, -12.1754, -12.5894]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[20., 21., 22., 23.]],\n",
      "\n",
      "        [[36., 37., 38., 39.]],\n",
      "\n",
      "        [[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[24., 25., 26., 27.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[ -7.3429,  -7.6863,  -8.0296],\n",
      "         [ 14.1811,  14.8657,  15.5504],\n",
      "         [ -0.7803,  -0.7696,  -0.7588],\n",
      "         [ 10.5051,  11.0192,  11.5334],\n",
      "         [  0.9306,   1.0106,   1.0905],\n",
      "         [ -2.7744,  -2.9012,  -3.0280],\n",
      "         [  4.6731,   4.9298,   5.1865],\n",
      "         [  8.8696,   9.2785,   9.6873],\n",
      "         [ -1.5413,  -1.5626,  -1.5838],\n",
      "         [ -8.4496,  -8.8636,  -9.2776]],\n",
      "\n",
      "        [[-12.8368, -13.1801, -13.5235],\n",
      "         [ 25.1354,  25.8200,  26.5047],\n",
      "         [ -0.6083,  -0.5976,  -0.5868],\n",
      "         [ 18.7313,  19.2454,  19.7595],\n",
      "         [  2.2096,   2.2895,   2.3695],\n",
      "         [ -4.8034,  -4.9302,  -5.0570],\n",
      "         [  8.7798,   9.0364,   9.2931],\n",
      "         [ 15.4107,  15.8195,  16.2284],\n",
      "         [ -1.8814,  -1.9026,  -1.9239],\n",
      "         [-15.0732, -15.4872, -15.9012]],\n",
      "\n",
      "        [[ -0.4755,  -0.8189,  -1.1623],\n",
      "         [  0.4882,   1.1729,   1.8575],\n",
      "         [ -0.9953,  -0.9846,  -0.9738],\n",
      "         [  0.2224,   0.7365,   1.2507],\n",
      "         [ -0.6681,  -0.5882,  -0.5082],\n",
      "         [ -0.2381,  -0.3649,  -0.4917],\n",
      "         [ -0.4602,  -0.2035,   0.0532],\n",
      "         [  0.6933,   1.1021,   1.5109],\n",
      "         [ -1.1162,  -1.1375,  -1.1587],\n",
      "         [ -0.1701,  -0.5840,  -0.9980]],\n",
      "\n",
      "        [[ -8.7164,  -9.0597,  -9.4031],\n",
      "         [ 16.9197,  17.6043,  18.2889],\n",
      "         [ -0.7373,  -0.7266,  -0.7158],\n",
      "         [ 12.5616,  13.0758,  13.5899],\n",
      "         [  1.2504,   1.3303,   1.4102],\n",
      "         [ -3.2816,  -3.4085,  -3.5353],\n",
      "         [  5.6998,   5.9565,   6.2131],\n",
      "         [ 10.5049,  10.9137,  11.3225],\n",
      "         [ -1.6263,  -1.6476,  -1.6688],\n",
      "         [-10.1055, -10.5195, -10.9335]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([2, 1, 4])\n",
      "tensor([[[16., 17., 18., 19.]],\n",
      "\n",
      "        [[32., 33., 34., 35.]]])\n",
      "torch.Size([2, 10, 3])\n",
      "tensor([[[ -5.9694,  -6.3128,  -6.6562],\n",
      "         [ 11.4425,  12.1272,  12.8118],\n",
      "         [ -0.8233,  -0.8126,  -0.8018],\n",
      "         [  8.4486,   8.9627,   9.4768],\n",
      "         [  0.6109,   0.6908,   0.7708],\n",
      "         [ -2.2671,  -2.3939,  -2.5208],\n",
      "         [  3.6465,   3.9031,   4.1598],\n",
      "         [  7.2344,   7.6432,   8.0520],\n",
      "         [ -1.4563,  -1.4776,  -1.4988],\n",
      "         [ -6.7937,  -7.2077,  -7.6217]],\n",
      "\n",
      "        [[-11.4633, -11.8067, -12.1500],\n",
      "         [ 22.3968,  23.0814,  23.7661],\n",
      "         [ -0.6513,  -0.6406,  -0.6298],\n",
      "         [ 16.6747,  17.1888,  17.7030],\n",
      "         [  1.8899,   1.9698,   2.0497],\n",
      "         [ -4.2961,  -4.4230,  -4.5498],\n",
      "         [  7.7531,   8.0098,   8.2664],\n",
      "         [ 13.7755,  14.1843,  14.5931],\n",
      "         [ -1.7964,  -1.8176,  -1.8389],\n",
      "         [-13.4173, -13.8313, -14.2453]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = nn.Conv1d(1, 10, 2)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "dl = DataLoader(dataset, batch_size=4, worker_init_fn=seed_worker, generator=g, shuffle=True)\n",
    "for i in range(2):\n",
    "    print(\"Epoch\", i)\n",
    "    for batch, label in dl:\n",
    "       print(batch.unsqueeze(1).shape)\n",
    "       print(batch.unsqueeze(1))\n",
    "       o = a(batch.unsqueeze(1))\n",
    "       print(o.shape)\n",
    "       print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data and the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/whole_sequence.fasta', 'r') as f:\n",
    "    seqs = list(SeqIO.parse(f, 'fasta'))\n",
    "seq = {s.id:str(s.seq) for s in seqs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(seq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EH1(72)': 'MLLPETRNLLDLMDAATRGGRPRLETLPHAVGRKAVDKMSEDGEADPPEVAEVANGGFAGPASEIRFRRYRPLGEAAGLLPTLIYYHGGGFVIGNIETHDSTCRRLANKSRCQVISIDYRLAPEHPFPAPIDDGIAAFRHIRDNAESFGADAARLAVGGDSAGGAMAAVVCQACRDAGETGPAFQMLIYPATDSSRESASRVAFAEGYFLSKALMDWFWEAYVPEDTDLTDLRLSPLLATDFTGLPPAFVLTAGYDPLRDEGRAYADRLIEAGIKTTYVNYPGTIHGFFSLTRFLSQGLKANDEAAAVMGAHFGT',\n",
       " 'EH2(71)': 'MGLQKLIVRTLMKLPESWILKLAGGTPVEIDGRTMDPRIQLLAAQGAKAPSMTSMSIEDARKSADEGLALLDAKPRRTVSILSRTIPGPAGDLHVRIYTPAGATGPLPGIVYYHMGGCVIGNLETCNTFCSILADDCRAIVVSVDYRLAPEHKFPAAMDDAVASFDWVSENAAALGIDPTRLGVGGDSAGGWLSAVVCQTRKAEGKTQPKAQLLIYPATDLDAKEGSMQSCAEIYPLTAEIMDWFMQQFLNSPEDAKDLKASPAHSEDLSGLAPALIMTAGFDVLRDQGEAYGNRLRDAGVPVTYRCYDSLSHAYTAFSGAVPAARQACEEIARDMARALG',\n",
       " 'EH3(69)': 'MPDTTSLNIADDVRMDPRLKAMLAAFPMMEQQTFQTREEQVANANTPEATAAREQLKMMMDMMDSEEFAPSDNLDISTREFTSSPDGNAIKIQFIRPKGKQKVPCVYYIHGGGMMIMSAFYGNYRAWGKMIANNGVAVAMVDFRNCLSPSSAPEVAPFPAGLNDCVSGLKWVSENADELSIDKNKIIIAGESGGGNLTLATGLKLKQDGNIDLVKGLYALCPYIAGKWPQDRFPSSSENNGIMIELHNNQGALAYGIEQLEAENPLAWPSFASAEDMQGLPPTVINVNECDPLRDEGIDFYRRLMAAGVPARCRQVMGTCHAGDMFVAVIPDVSADTAADIARTAKGG',\n",
       " 'CalB(68)': 'MALPSGSDPAFSQPKSVLDAGLTCQGASPSSVSKPILLVPGTGTTGPQSFDSNWIPLSTQLGYTPCWISPPPFMLNDTQVNTEYMVNAITALYAGSGNNKLPVLTWSQGGLVAQWGLTFFPSIRSKVDRLMAFAPDYKGTVLAGPLDALAVSAPSVWQQTTGSALTTALRNAGGLTQIVPTTNLYSATDEIVQPQVSNSPLDSSYLFNGKNVQAQAVCGPLFVIDHAGSLTSQFSYVVGRSALRSTTGQARSADYGITDCNPLPANDLTPEQKVAAAALLAPAAAAIVAGPKQNCEPDLMPYARPFAVGKRTCSGIVTPLE',\n",
       " 'EH4(67)': 'MSLQRMIVRTLLKLPDGLLVKMSGGKPLEIDGRTLDARVQLLASQGAKAPSMTTLPIEEARKGADDGLAMLDAKPRRNVSILSRSIPGPEGELHVRVYTPAGATGPLPGIVYYHMGGCVIGGLETCNTFCSILAEDCRAIVVSVDYRLAPEHKFPAAIDDAIASYDWVYQNATALGIDNTRLGLGGDSAGGWLSAVVCQHRKREGLPQPKAQLLIYPATDLQMTGGSMESCKDVYPLTREIMDWFMAQFLTSDADRSDWRGSPGQTADLSGLAPAIVATAGFDVLRDQGEAYANKLKAAGVPASYHCYDSLAHAFTAFSGTVPAAKQACEELAREMAKALNA',\n",
       " 'EH5(67)': 'MALNSQAEELLKRAAESGTPGLGEGTPEEGRAIFATTTQLLGLPAPDVKDTKEIQISGPNGPIRTLVITPDGVETNNLPLFIYYHGGGWVIGSPETHYEECCYYANEAQCIVLVPDYRLAPEYPFPAAPEDCYAVLQWAADNAESLGADKSRIAVGGDSAGGNLSAVVAQMTQQRNGPELALQLLIYPATRMGADTQSYKDFEDGYFLTAKAMNWFFGHYLKKAEDWDNLLASPLLNDDLAGLAPAYVVTAGFDPLRDEGRAYADKLKAAGVPVEYVCYEGQIHGFASMAGALDEARSFLDEAAKVLRKAFNK',\n",
       " 'EH6(66)': 'MPLHPQIEGLLQQMAAAGGKGFHQMEVDECRQTFGGLLNSLPPSQQKIASAQDRGIPSPNGPVKVRVYTPEGSGPFPVMAYFHGGGWVIGDLETHDSLCRELCGAVGMVVVSVDYRLAPEHKFPAAPDDCVAVTRWIAANAAALNADASRIAVGGDSAGGNLAAVVAQRLRDEDALKLAAQLLIYPVVHLDGVATPSMIENAEGYLLTRKDMEWFGGHYLASPADGQNASASPILAKSLAGLPPALVLTCEFDPLRDEGEKYGKALQAAGVPTTISRHDGTIHATFSFFTALEPGRRMADEAIRWLKEQLVK',\n",
       " 'EH7(64)': 'MEFPMAQSNIIAGMDLNRLDRIAEHLDRAYLHPGKLAGTMTLVARRGEVVYCQAQGLRDVERQLPVERDTLFRIYSMTKPITSIALMQLYEQGRFLLDEPVHKYIPTWKNLRVYKTGSHPQMLTTAPQRPMTIRDLLTHQSGLTYGFMNRTNVDAAYRSLKLDGGPGHTLDRLIDELARLPLEFSPGTAWNYSVATDVCGYLVQLLSGMSLDDYFSKHIFQPLGMPDTFFTVPAEKLSRFAACYEYQPGDSFSLQDDPQGSAFAKAHGYLSGGGGLVSCVDDYYRFAQALANGGELDGARIIGRKTLEFMRMNHLPDNKGLPDVAIGSFSETPYDGTGFGLGFSVKLDVAKSQTVGSVGEYGWGGMASTNFFIDPEEDLLMVFMTQLIPSSTYAVRQELRAIINGALVD',\n",
       " 'EH8(63)': 'MNPAVIERATVRALMSLPGPVLERLAAGLETHSRPHLDSRLRFLLALSGAKPTLDSGTVEQARQIYRSTLALLDMAPVSLPVVVDHQVSMEDGSQILVRRYRPADAPLVSPAIMFFHGGGFTIGGVEEYDRLCRYIAKRTNAVVLSVDYRLAPEHPAPAGMDDALEAWRWLLNNTAQLGLDPNRLAVMGDSAGGCMSAVVSQQAKLAGLALPALQVLIYPTTDAALAHPSVQTLGQGFGLDIPLLTWFRGHFVQDPAVIEDYRVSPLRNPDLTGLPEAIVITATDPLRDEGLEYAQKLREAGNTVTSLDYPELIHGFISMGGVVPAARKAINDICVETKRRL',\n",
       " 'EH9(61)': 'MEKKMALDKQAAEILKRAEESDTPGLGEGSPAEGREVFAGTTALLGLPTPEGQRISEVQIPGPSGDIRTRIIHPLEGLADNLPILIYYHGGGWVIGSPETHEGETCFYANEANCVVLVPDYRLAPEDPFPAAPDDCYAVLEWANANAETFGGDASRIAVAGDSAGGNLSAVVSQMAHANNGPDIALQLLIYPATRMGATTESYREFNDGYFLTGKAMDWFFNHYLKRPEDWDALKASPLLAPDLSGLPPAYIMTAGFDPLRDEGKAYAERLQQAGVPVDYVCYEEQIHGFVSMAGALDQGKQFLREAAAVLRRAFTS'}"
      ]
     },
     "execution_count": 11,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = islice(a, 10)\n",
    "dict(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the tokenizer and the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "low_cpu_mem_usage: when loading try not to use more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", low_mem_usage=True)\n",
    "tok = tokenizer(list(seq.values())[:2], padding=True, truncation=True, return_tensors=\"pt\", is_split_into_words=False)\n",
    "tok = tok.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    }
   ],
   "source": [
    "model_8bit = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, device_map=\"auto\", load_in_8bit=True)\n",
    "#model.to(device)\n",
    "#model.eval()\n",
    "model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, device_map=\"cpu\")\n",
    "model_masked_16 = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, device_map=\"cpu\", torch_dtype=torch.float16)\n",
    "model_16 = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, device_map=\"cpu\", torch_dtype=torch.float16) \n",
    "# most models might not be able to do inference with float 16. Its errors is lower than bfloat16 but you cannot run it in CPUs maybe\n",
    "model_masked = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, device_map=\"cpu\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('',\n",
       " EsmModel(\n",
       "   (embeddings): EsmEmbeddings(\n",
       "     (word_embeddings): Embedding(33, 320, padding_idx=1)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "     (position_embeddings): Embedding(1026, 320, padding_idx=1)\n",
       "   )\n",
       "   (encoder): EsmEncoder(\n",
       "     (layer): ModuleList(\n",
       "       (0-5): 6 x EsmLayer(\n",
       "         (attention): EsmAttention(\n",
       "           (self): EsmSelfAttention(\n",
       "             (query): Linear(in_features=320, out_features=320, bias=True)\n",
       "             (key): Linear(in_features=320, out_features=320, bias=True)\n",
       "             (value): Linear(in_features=320, out_features=320, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "             (rotary_embeddings): RotaryEmbedding()\n",
       "           )\n",
       "           (output): EsmSelfOutput(\n",
       "             (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "         (intermediate): EsmIntermediate(\n",
       "           (dense): Linear(in_features=320, out_features=1280, bias=True)\n",
       "         )\n",
       "         (output): EsmOutput(\n",
       "           (dense): Linear(in_features=1280, out_features=320, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "     (emb_layer_norm_after): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (contact_head): EsmContactPredictionHead(\n",
       "     (regression): Linear(in_features=120, out_features=1, bias=True)\n",
       "     (activation): Sigmoid()\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 48,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_modules())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=30, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.333333343267440795898437500000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1/3, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.333251953125000000000000000000, dtype=torch.float16)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1/3, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.333984375000000000000000000000, dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1/3, dtype=torch.bfloat16) # los numeros que puede presentar antes de que sea 0 y la precision que puede presentar es diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 15.2477,  -7.5770,  -6.3456,  ..., -15.4048, -15.6385,  -7.5723],\n",
       "         [ -9.7658, -16.5052,  -9.5490,  ..., -15.9087, -16.1523, -16.4937],\n",
       "         [-12.1465, -22.2140, -12.5623,  ..., -15.8097, -15.8878, -22.1935],\n",
       "         ...,\n",
       "         [ -5.5602,  -6.6518,  14.4635,  ..., -16.7472, -16.5519,  -6.6859],\n",
       "         [ -5.3854,  -6.4475,  16.6540,  ..., -16.7547, -16.5586,  -6.4803],\n",
       "         [ -5.4969,  -6.6457,  16.6575,  ..., -16.6794, -16.5023,  -6.6868]],\n",
       "\n",
       "        [[ 16.1664,  -6.1153,  -6.5335,  ..., -15.2296, -15.4523,  -6.1025],\n",
       "         [ -8.9726, -16.1343,  -7.6063,  ..., -15.9684, -16.2367, -16.1393],\n",
       "         [-11.5151, -19.6775, -10.5682,  ..., -15.8286, -15.9348, -19.6637],\n",
       "         ...,\n",
       "         [-10.4293, -21.1545, -12.9438,  ..., -16.0008, -16.0468, -21.1782],\n",
       "         [-12.7677, -21.3681, -12.9532,  ..., -16.2232, -16.3621, -21.3540],\n",
       "         [ -6.0046,  -5.6860,  17.9882,  ..., -16.7294, -16.6201,  -5.7410]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_masked(**tok)\n",
    "output.logits# logits es lo que le das al softmax para que lo convierta en probabilidad -> softmax(logits) es el output the last linear model\n",
    "# y que es last hidden state entonces? Es muy diferente a los logits? El shape es diferente -> para cada position devuelve la probabilidad de que sea uno de los tokens\n",
    "# EL maskedLM y el automodel hidden state es lo mismo -> pero la logits cambia. Cual deber√≠a usar para el embedding?\n",
    "#output.hidden_states[-1] # en el caso de MASkedLM si no le especifico de devolver hidden states, no los devuelve, pero en el caso de automodel si los devuelve aun sin lo del hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False, False, False, False,\n",
       "         True],\n",
       "       [False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(F.softmax(output.logits, dim=0).detach().numpy(), axis=-1) == np.argmax(F.softmax(output_16.logits, dim=0).detach().numpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 21,  4, 13, 14,  9, 11, 10, 17,  4,  4, 13,  4, 20, 13,  5,\n",
       "         5, 11, 10,  6,  6, 10, 14, 10,  4,  9, 22,  4, 14, 21,  5,  7,\n",
       "        22, 22, 15,  5,  7, 13, 15, 20,  8,  9, 13,  6, 18,  5, 13, 14,\n",
       "         1,  9,  7,  5,  2,  7,  5,  2,  1,  6, 18,  5,  6, 14,  5,  6,\n",
       "         9, 12,  1, 18, 10, 12, 19, 10, 14,  4,  6,  9,  5,  5,  6,  4,\n",
       "         4, 14,  0,  4, 12, 19, 19, 21,  1,  6,  6, 18,  7, 12,  6, 17,\n",
       "        12,  9, 11, 21, 13,  8, 22, 23, 10, 10,  4,  5,  9,  9,  8, 10,\n",
       "        23, 16,  7, 12,  8, 12, 13, 19, 10,  4,  5, 14,  9, 21, 14, 18,\n",
       "         1,  5,  1, 12, 13, 13,  6, 12,  2,  5, 18, 10, 22, 12, 10, 13,\n",
       "        17,  5,  9,  8, 18,  6,  5, 13, 14,  5, 10,  4,  1,  7,  6,  6,\n",
       "         6,  0,  5,  6,  1, 17, 20,  5,  5,  7,  7, 23, 16, 19, 23, 10,\n",
       "        13, 13,  6, 19, 14, 14, 14, 10, 15, 16, 20,  4, 12, 19, 14, 22,\n",
       "        11, 13, 10, 10, 14,  9,  8, 14, 14, 13, 14, 14, 18,  5,  9,  6,\n",
       "        19,  9,  4, 13, 15,  9,  9, 20, 13, 22, 18, 22,  9,  2, 19,  7,\n",
       "         6,  6, 13, 11, 13,  4, 11, 13, 14, 10,  4,  8, 14, 10,  4,  2,\n",
       "        11, 13, 18, 11,  6,  4, 14, 14,  5,  4,  7,  2,  1,  2,  1,  1,\n",
       "         1,  1,  4, 10, 13,  9,  6, 10, 10, 19,  5, 13, 10,  1, 12,  9,\n",
       "         5,  6, 12, 13, 11,  9, 19, 10, 10, 19, 14,  6, 20, 12, 21,  6,\n",
       "        18, 18,  8,  4, 11, 14, 18,  4, 13, 14,  2, 14, 12,  5,  2, 13,\n",
       "         9,  5,  5,  1,  1, 20,  4,  5, 21, 18,  6, 11,  1, 24, 24, 24,\n",
       "        24, 10, 10, 23, 14, 14, 14,  6, 14, 14, 14, 14, 14, 14,  2, 14,\n",
       "         1,  1,  1,  1,  1,  1, 11],\n",
       "       [ 1,  2,  6,  1, 16, 15,  4, 12,  7, 10, 11,  4, 20, 15,  4, 14,\n",
       "         9,  8, 22, 12,  4, 15,  4,  5,  6,  6, 15, 14,  7,  9, 12, 13,\n",
       "        14, 15, 11, 20, 13, 14, 10, 12, 16,  4,  4,  5,  5, 16,  6,  5,\n",
       "        15,  5, 14,  8, 20, 11,  8, 20,  8, 12,  9, 13,  5, 10, 15, 22,\n",
       "         5, 13,  9,  6, 14,  5,  4,  4, 13,  1, 15,  1, 10, 10, 11,  7,\n",
       "         8, 12,  9,  8, 10, 14, 15, 14, 11, 14, 13,  6, 13,  0, 21,  7,\n",
       "         1, 12, 19,  2, 14,  5,  6,  9,  1,  1, 14,  4, 14,  6, 12,  7,\n",
       "         1, 19, 21,  6,  6,  6, 18,  7, 12,  6, 17,  4, 19, 11, 19, 17,\n",
       "        11, 18, 23,  8, 12,  4,  5, 13, 13, 15, 10,  5, 12, 14,  7,  8,\n",
       "         7, 13, 19, 10,  1,  5, 14,  9, 21, 14, 18, 14, 15, 15, 20, 13,\n",
       "         1,  5, 22,  9,  7, 18, 13, 22,  7, 15,  9, 17,  5, 14, 13,  4,\n",
       "         6, 12, 13, 14, 17, 10, 24,  1,  7,  1,  1, 13,  8,  5,  6,  6,\n",
       "        22,  4,  2,  5,  7,  7, 23, 16, 10,  3,  3, 16,  9,  6, 15, 11,\n",
       "        16,  1, 15,  5, 16,  4,  0, 12, 19, 14,  1, 11,  1,  4, 13,  5,\n",
       "        15,  0,  6,  8, 20, 16,  1, 23,  2,  9, 12, 19, 22,  6, 11, 14,\n",
       "        22, 12, 20, 13, 22, 18, 20, 16, 16, 14,  6,  6, 15, 14,  9, 13,\n",
       "         5, 15, 13, 14, 19,  5,  1, 14, 14, 21,  8,  9, 13, 14,  8,  6,\n",
       "         4, 14, 14,  0,  4, 12, 20, 11,  1,  1, 18, 13, 14,  4, 10,  1,\n",
       "        16,  6,  9,  5, 19,  6, 17,  1,  4, 10, 13,  5,  6,  7, 14,  7,\n",
       "        11, 19, 10, 23, 19, 13,  8,  4,  8, 21,  5, 19, 11,  5, 18,  8,\n",
       "         6,  5,  7, 14,  5,  5, 10, 16,  5, 23,  9,  9, 12,  0, 10, 13,\n",
       "        20,  5, 10,  5,  4,  6, 22]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(F.softmax(output_16.logits, dim=0).detach().numpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_16 = model_masked_16(**tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0912, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output.hidden_states[-1] - output_16.hidden_states[-1]).max(axis=1)[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max difference: 0.01247859\n",
      "mean difference: 0.00063062285\n"
     ]
    }
   ],
   "source": [
    "model_masked_16 = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, \n",
    "                                                       device_map=\"cpu\", torch_dtype=torch.float16)\n",
    "\n",
    "model_masked = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, \n",
    "                                                    device_map=\"cpu\", torch_dtype=torch.float32)\n",
    "\n",
    "output = model_masked(**tok)\n",
    "output_16 = model_masked_16(**tok)\n",
    "\n",
    "print(\"max difference:\", (output.hidden_states[-1] - output_16.hidden_states[-1]).max().detach().numpy())\n",
    "print(\"mean difference:\", (output.hidden_states[-1] - output_16.hidden_states[-1]).abs().mean().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 343, 320])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**tok)\n",
    "output # si no le especificas hidden states -> tampoco tiene hidden states, sino que tiene last_hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1421,  0.5840, -0.0724,  ...,  1.1748, -0.0931, -0.4209],\n",
       "         [ 0.4133,  0.0937, -0.1658,  ...,  0.8398, -0.2219, -0.2437],\n",
       "         [ 0.0767, -0.5088, -0.0298,  ...,  0.3887, -0.0302,  0.1070],\n",
       "         ...,\n",
       "         [-0.2573,  0.2483,  0.5522,  ...,  0.6455, -0.5259, -0.0944],\n",
       "         [-0.3516,  0.2590,  0.5864,  ...,  0.4985, -0.5669, -0.1550],\n",
       "         [-0.3301,  0.2368,  0.2407,  ...,  0.4675, -0.6846, -0.3098]],\n",
       "\n",
       "        [[ 0.0927,  0.6987, -0.0489,  ...,  1.0352, -0.1703, -0.3040],\n",
       "         [ 0.3230,  0.4792, -0.1464,  ...,  0.7700, -0.2129, -0.2917],\n",
       "         [ 0.0061, -0.2739,  0.2622,  ..., -0.0435,  0.2888,  0.1104],\n",
       "         ...,\n",
       "         [-0.4729, -0.2120, -0.2720,  ...,  0.9448, -0.3599,  0.2312],\n",
       "         [-0.0944, -0.4836,  0.0655,  ...,  0.3899, -0.1250, -0.1101],\n",
       "         [-0.0054,  0.0670,  0.1100,  ...,  0.6562, -0.6016, -0.2551]]],\n",
       "       dtype=torch.float16, grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_16 = model_16(**tok)\n",
    "output_16.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.483202"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_float16.get_memory_footprint()/1e+6\n",
    "#model.get_memory_footprint()/1e+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_16 = output.last_hidden_state - output_16.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0125, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_16.max(axis=1).values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 15.0938,  -7.5859,  -6.3984,  ..., -15.4062, -15.6328,  -7.5781],\n",
       "         [ -9.7422, -16.4844,  -9.3047,  ..., -15.8906, -16.1406, -16.4688],\n",
       "         [-11.9688, -21.8438, -12.3438,  ..., -15.7969, -15.8750, -21.8281],\n",
       "         ...,\n",
       "         [ -5.5430,  -6.7969,  14.7812,  ..., -16.7656, -16.5781,  -6.8281],\n",
       "         [ -5.4414,  -6.3516,  17.0000,  ..., -16.7031, -16.5156,  -6.3867],\n",
       "         [ -5.4102,  -6.6562,  16.5625,  ..., -16.6719, -16.4844,  -6.6953]],\n",
       "\n",
       "        [[ 16.1562,  -5.9922,  -6.4141,  ..., -15.2656, -15.4844,  -5.9805],\n",
       "         [ -9.0000, -15.7500,  -7.1562,  ..., -15.9609, -16.2344, -15.7500],\n",
       "         [-11.6250, -19.8281, -10.8594,  ..., -15.8203, -15.9297, -19.8125],\n",
       "         ...,\n",
       "         [-10.2578, -20.8750, -12.7188,  ..., -15.9688, -16.0312, -20.9062],\n",
       "         [-12.6641, -21.1250, -12.9375,  ..., -16.2031, -16.3438, -21.1094],\n",
       "         [ -6.0078,  -5.7773,  17.8594,  ..., -16.7188, -16.5938,  -5.8281]]],\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_8bit = model_8bit(**tok)\n",
    "output_8bit.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = output.logits - output_8bit.logits\n",
    "state = output.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4023, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference[0,:,-11].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7880e-05, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([343, 160])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.AvgPool1d(2)(output.last_hidden_state[-1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the attention mask to remove the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "mask = tok[\"attention_mask\"].bool()\n",
    "for num, x in enumerate(output.last_hidden_state):\n",
    "    masked_x = x[mask[num]]\n",
    "    results[num] = masked_x.mean(dim=0).detach().cpu().numpy()\n",
    "    # detach removes the tensor from the computation graph (the gradient won't be computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(results[0], dim=0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data2.csv\"\n",
    "embeddings = pd.DataFrame(results).T\n",
    "embeddings.to_csv(path, mode='a', header=not Path(path).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([343, 320])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[tok[\"attention_mask\"].bool()[1]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt the code to Load large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "# https://huggingface.co/docs/datasets/loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to load files within datasets -> from local or remote files (in these formats json, csv, text, parquet)  \n",
    "Since we have a fasta file that is not supported (because it will treat each line as a row so it will double the rows, but in fasta the first line is an id).  \n",
    "So we can process it in-memory to pandas, generators, dictionaries or list of dictionaries and use Datasets instead of load_dataset.  \n",
    "The load dataset returns a dataset dict with different splits (train, test, val) as keys and then a dataset object as values.\n",
    "\n",
    "But we are using a dataset object directl\n",
    "\n",
    "To load fasta files use from generator beacause it is in-memory and the file might be too large to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 294 examples [00:00, 6184.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 294\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = load_dataset(\"text\", data_files=\"../data/whole_sequence.fasta\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_generator(fasta_file: str=\"../data/whole_sequence.fasta\"):\n",
    "    with open(fasta_file, 'r') as f:\n",
    "        seqs = SeqIO.parse(f, 'fasta')\n",
    "        for seq in seqs:\n",
    "            yield {\"id\":seq.id, \"seq\":str(seq.seq)}\n",
    "\n",
    "with open(\"../data/whole_sequence.fasta\", 'r') as f:\n",
    "    seqs = SeqIO.parse(f, 'fasta')\n",
    "    d = pd.Series({s.id:str(s.seq) for s in seqs}).to_frame()\n",
    "    d.columns = [\"sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 147 examples [00:00, 21001.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'seq'],\n",
       "    num_rows: 147\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Dataset.from_generator(fasta_generator, gen_kwargs={\"fasta_file\":\"../data/whole_sequence.fasta\"})\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process or tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use map to apply the tokenizer function to the entire dataset\n",
    "The map will create and add the new columns ('input_ids', 'attention_mask') coming from the tokenizer to the datatset   \n",
    "but you will have to change its format to torch tensors for the models to read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = b.map(lambda examples: tokenizer(examples[\"seq\"], return_tensors=\"pt\",padding=True, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = dataset.select_columns([\"id\",\"input_ids\", \"attention_mask\"])\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to extract the embeddings use the dataloader from pytorch to create the batches for you  \n",
    "It will only return the input_ids and the attention mask (the ids are lost, so yoou don't know which sequence is which)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 0, 20, 10,  ...,  1,  1,  1],\n",
       "         [ 0, 20, 15,  ...,  1,  1,  1],\n",
       "         [ 0, 20, 15,  ...,  1,  1,  1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4)\n",
    "for batch in dataloader:\n",
    "    u = batch\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BioML.deep.embeddings as emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f39e453b894286bd6382344628cda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = emb.TokenizeFasta(emb.LLMConfig()).tokenize(\"../data/whole_sequence.fasta\")\n",
    "embed = emb.ExtractEmbeddings(emb.LLMConfig())\n",
    "seq_keys = list(data[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, batch in enumerate(DataLoader(data, batch_size=batch_size)):\n",
    "    batch_seq_keys = seq_keys[num*batch_size:(num+1)*batch_size]\n",
    "    results = embed.extract(batch_seq_keys, batch)\n",
    "    #embed.save(results, \"../data/embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(\"../data/embeddings.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways to create emebeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = torch.nn.Linear(320, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mattention_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m attention_weights\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "attention_scores = attention_weights(output.hidden_states[-1])\n",
    "attention_weights = torch.softmax(attention_scores, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 343, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 109760])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp = output.hidden_states[-1].reshape(output.hidden_states[-1].shape[0], -1)\n",
    "_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1419,  0.5839, -0.0722,  ...,  0.4682, -0.6849, -0.3094],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, -107712)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0, 2048 - _temp.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.nn.functional.pad(_temp, (0, 2048 - _temp.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1419,  0.5839, -0.0722,  0.3390, -0.1853, -0.0982, -0.9235,  0.1019,\n",
       "        -0.4527, -0.6959], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109670"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(o[0].detach().numpy()).intersection(_temp[0].detach().numpy()))xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(output.hidden_states[-1][0][0].detach().numpy()).intersection(_temp[0][:100].detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training using the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BioML.models.regression as regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(\"../data/embeddings.csv\", index_col=0)\n",
    "label = list(range(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-02-2024 12:07:16 INFO ------------------------------------------------------------------------------\n",
      "23-02-2024 12:07:16 INFO PycaretInterface parameters\n",
      "23-02-2024 12:07:16 INFO Seed: 200\n",
      "23-02-2024 12:07:16 INFO Budget time: 20\n",
      "23-02-2024 12:07:16 INFO The number of models to select: 3\n",
      "23-02-2024 12:07:16 INFO Output path: regression_training\n",
      "23-02-2024 12:07:16 INFO ----------------Trainer inputs-------------------------\n",
      "23-02-2024 12:07:16 INFO Number of kfolds: 5\n",
      "23-02-2024 12:07:16 INFO Number of iterations: 30\n"
     ]
    }
   ],
   "source": [
    "data = regression.DataParser(\"../data/embeddings.csv\", label)\n",
    "experiment = regression.PycaretInterface(\"regression\", 200, scaler= \"zscore\", budget_time=20, best_model=3, \n",
    "                                        output_path=\"regression_training\", optimize=\"RMSE\")\n",
    "\n",
    "regressor = regression.Regressor(test_size=0.2, optimize=\"RMSE\")\n",
    "training = regression.Trainer(experiment, regressor, 5, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data according to sequence similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = regression.split.ClusterSpliter(\"../data/resultsDB_clu.tsv\", 5, random_state=experiment.seed, test_size=0.2)\n",
    "X_train, X_test = c.train_test_split(data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/23 12:18:52 INFO mlflow.tracking.fluent: Experiment with name 'Regression' does not exist. Creating a new experiment.\n",
      "23-02-2024 12:18:53 INFO --------------------------------------------------------\n",
      "23-02-2024 12:18:53 INFO Training regression models\n",
      "23-02-2024 12:18:53 INFO The models used ['lr', 'lasso', 'ridge', 'en', 'lar', 'llar', 'omp', 'br', 'par', 'huber', 'svm', 'knn', 'dt', 'rf', 'et', 'gbr', 'mlp', 'xgboost', 'catboost', 'dummy']\n",
      "23-02-2024 12:18:53 INFO Time budget is 20 minutes\n",
      "23-02-2024 12:20:27 INFO Training over: Total runtime 1.565 minutes\n",
      "23-02-2024 12:20:27 INFO Analyse the best models and plotting them\n",
      "23-02-2024 12:20:27 INFO Analyse the top 1 model: catboost\n",
      "23-02-2024 12:24:10 INFO Analyse the top 2 model: br\n",
      "23-02-2024 12:24:13 INFO Analyse the top 3 model: rf\n",
      "23-02-2024 12:24:27 INFO --------Stacking the best models--------\n",
      "23-02-2024 12:24:27 INFO ----------Stacking the best models--------------\n",
      "23-02-2024 12:27:58 INFO --------Creating an ensemble model--------\n",
      "23-02-2024 12:27:58 INFO ----------Creating a majority voting model--------------\n",
      "23-02-2024 12:27:58 INFO fold: 5\n",
      "23-02-2024 12:27:58 INFO weights: None\n",
      "23-02-2024 12:28:45 INFO --------Retuning the best models--------\n",
      "23-02-2024 12:28:45 INFO Retuning catboost\n",
      "23-02-2024 12:28:45 INFO ---------Retuning the best models--------------\n",
      "23-02-2024 12:28:45 INFO num_iter: 30\n",
      "23-02-2024 12:28:45 INFO fold: 5\n",
      "23-02-2024 12:45:00 INFO Retuning br\n",
      "23-02-2024 12:45:00 INFO ---------Retuning the best models--------------\n",
      "23-02-2024 12:45:00 INFO num_iter: 30\n",
      "23-02-2024 12:45:00 INFO fold: 5\n",
      "23-02-2024 12:45:16 INFO Retuning rf\n",
      "23-02-2024 12:45:16 INFO ---------Retuning the best models--------------\n",
      "23-02-2024 12:45:16 INFO num_iter: 30\n",
      "23-02-2024 12:45:16 INFO fold: 5\n",
      "23-02-2024 12:46:25 INFO --------Stacking the best models--------\n",
      "23-02-2024 12:46:25 INFO ----------Stacking the best models--------------\n",
      "23-02-2024 12:46:44 INFO --------Creating an ensemble model--------\n",
      "23-02-2024 12:46:44 INFO ----------Creating a majority voting model--------------\n",
      "23-02-2024 12:46:44 INFO fold: 5\n",
      "23-02-2024 12:46:44 INFO weights: None\n"
     ]
    }
   ],
   "source": [
    "results, models_dict = training.generate_training_results(X_train, data.label, True,\n",
    "                                                          test_data=X_test, fold_strategy=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioml_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
