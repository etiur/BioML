{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, BitsAndBytesConfig, AutoModelForSequenceClassification\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "# https://huggingface.co/blog/AmelieSchreiber/esmbind\n",
    "# the minimum for the ESM2 is 650M if we want better performance than ESM1b with 650M as well.\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "import torch.nn.functional as F\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.arange(40, dtype=torch.float32).view(10, 4), torch.tensor([i for i in range(10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(40).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[12., 13., 14., 15.]],\n",
      "\n",
      "        [[28., 29., 30., 31.]],\n",
      "\n",
      "        [[20., 21., 22., 23.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[ 12.9956,  14.0420,  15.0884],\n",
      "         [ 11.4176,  12.3456,  13.2735],\n",
      "         [ -9.6122, -10.3326, -11.0529],\n",
      "         [ -1.6359,  -1.8254,  -2.0149],\n",
      "         [  5.0438,   5.3842,   5.7246],\n",
      "         [  0.7708,   0.8625,   0.9543],\n",
      "         [  8.8450,   9.5876,  10.3303],\n",
      "         [  8.6126,   9.3116,  10.0106],\n",
      "         [  6.2343,   6.7019,   7.1694],\n",
      "         [ -8.3430,  -9.0782,  -9.8133]],\n",
      "\n",
      "        [[ 29.7380,  30.7844,  31.8308],\n",
      "         [ 26.2647,  27.1926,  28.1205],\n",
      "         [-21.1378, -21.8582, -22.5785],\n",
      "         [ -4.6684,  -4.8579,  -5.0474],\n",
      "         [ 10.4907,  10.8312,  11.1716],\n",
      "         [  2.2389,   2.3306,   2.4224],\n",
      "         [ 20.7272,  21.4699,  22.2125],\n",
      "         [ 19.7959,  20.4949,  21.1938],\n",
      "         [ 13.7148,  14.1824,  14.6499],\n",
      "         [-20.1057, -20.8408, -21.5760]],\n",
      "\n",
      "        [[ 21.3668,  22.4132,  23.4596],\n",
      "         [ 18.8411,  19.7691,  20.6970],\n",
      "         [-15.3750, -16.0954, -16.8157],\n",
      "         [ -3.1521,  -3.3417,  -3.5312],\n",
      "         [  7.7672,   8.1077,   8.4481],\n",
      "         [  1.5048,   1.5966,   1.6883],\n",
      "         [ 14.7861,  15.5287,  16.2714],\n",
      "         [ 14.2043,  14.9032,  15.6022],\n",
      "         [  9.9746,  10.4421,  10.9097],\n",
      "         [-14.2243, -14.9595, -15.6947]],\n",
      "\n",
      "        [[  8.8100,   9.8564,  10.9028],\n",
      "         [  7.7059,   8.6338,   9.5618],\n",
      "         [ -6.7308,  -7.4512,  -8.1715],\n",
      "         [ -0.8777,  -1.0673,  -1.2568],\n",
      "         [  3.6820,   4.0224,   4.3629],\n",
      "         [  0.4038,   0.4955,   0.5873],\n",
      "         [  5.8744,   6.6170,   7.3597],\n",
      "         [  5.8168,   6.5158,   7.2147],\n",
      "         [  4.3642,   4.8318,   5.2993],\n",
      "         [ -5.4023,  -6.1375,  -6.8727]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[32., 33., 34., 35.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[24., 25., 26., 27.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[  0.4389,   1.4852,   2.5316],\n",
      "         [  0.2824,   1.2103,   2.1382],\n",
      "         [ -0.9680,  -1.6884,  -2.4087],\n",
      "         [  0.6385,   0.4490,   0.2594],\n",
      "         [  0.9585,   1.2990,   1.6394],\n",
      "         [ -0.3303,  -0.2385,  -0.1468],\n",
      "         [ -0.0667,   0.6759,   1.4185],\n",
      "         [  0.2252,   0.9242,   1.6231],\n",
      "         [  0.6240,   1.0915,   1.5590],\n",
      "         [  0.4790,  -0.2562,  -0.9913]],\n",
      "\n",
      "        [[ 33.9236,  34.9700,  36.0164],\n",
      "         [ 29.9764,  30.9043,  31.8323],\n",
      "         [-24.0192, -24.7396, -25.4599],\n",
      "         [ -5.4265,  -5.6160,  -5.8056],\n",
      "         [ 11.8525,  12.1929,  12.5333],\n",
      "         [  2.6059,   2.6976,   2.7894],\n",
      "         [ 23.6978,  24.4405,  25.1831],\n",
      "         [ 22.5917,  23.2907,  23.9896],\n",
      "         [ 15.5850,  16.0525,  16.5200],\n",
      "         [-23.0463, -23.7815, -24.5167]],\n",
      "\n",
      "        [[  4.6244,   5.6708,   6.7172],\n",
      "         [  3.9941,   4.9221,   5.8500],\n",
      "         [ -3.8494,  -4.5698,  -5.2901],\n",
      "         [ -0.1196,  -0.3092,  -0.4987],\n",
      "         [  2.3203,   2.6607,   3.0011],\n",
      "         [  0.0367,   0.1285,   0.2202],\n",
      "         [  2.9038,   3.6465,   4.3891],\n",
      "         [  3.0210,   3.7200,   4.4189],\n",
      "         [  2.4941,   2.9616,   3.4292],\n",
      "         [ -2.4617,  -3.1968,  -3.9320]],\n",
      "\n",
      "        [[ 25.5524,  26.5988,  27.6452],\n",
      "         [ 22.5529,  23.4808,  24.4088],\n",
      "         [-18.2564, -18.9768, -19.6971],\n",
      "         [ -3.9103,  -4.0998,  -4.2893],\n",
      "         [  9.1290,   9.4694,   9.8099],\n",
      "         [  1.8718,   1.9636,   2.0553],\n",
      "         [ 17.7567,  18.4993,  19.2420],\n",
      "         [ 17.0001,  17.6990,  18.3980],\n",
      "         [ 11.8447,  12.3122,  12.7798],\n",
      "         [-17.1650, -17.9002, -18.6353]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([2, 1, 4])\n",
      "tensor([[[36., 37., 38., 39.]],\n",
      "\n",
      "        [[16., 17., 18., 19.]]])\n",
      "torch.Size([2, 10, 3])\n",
      "tensor([[[ 38.1092,  39.1556,  40.2020],\n",
      "         [ 33.6882,  34.6161,  35.5440],\n",
      "         [-26.9006, -27.6210, -28.3413],\n",
      "         [ -6.1846,  -6.3742,  -6.5637],\n",
      "         [ 13.2142,  13.5547,  13.8951],\n",
      "         [  2.9729,   3.0646,   3.1564],\n",
      "         [ 26.6684,  27.4110,  28.1537],\n",
      "         [ 25.3875,  26.0865,  26.7854],\n",
      "         [ 17.4551,  17.9226,  18.3901],\n",
      "         [-25.9870, -26.7222, -27.4573]],\n",
      "\n",
      "        [[ 17.1812,  18.2276,  19.2740],\n",
      "         [ 15.1294,  16.0573,  16.9853],\n",
      "         [-12.4936, -13.2140, -13.9343],\n",
      "         [ -2.3940,  -2.5835,  -2.7731],\n",
      "         [  6.4055,   6.7459,   7.0864],\n",
      "         [  1.1378,   1.2295,   1.3213],\n",
      "         [ 11.8155,  12.5582,  13.3008],\n",
      "         [ 11.4085,  12.1074,  12.8064],\n",
      "         [  8.1045,   8.5720,   9.0395],\n",
      "         [-11.2837, -12.0188, -12.7540]]], grad_fn=<ConvolutionBackward0>)\n",
      "Epoch 1\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[12., 13., 14., 15.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[28., 29., 30., 31.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[  4.6244,   5.6708,   6.7172],\n",
      "         [  3.9941,   4.9221,   5.8500],\n",
      "         [ -3.8494,  -4.5698,  -5.2901],\n",
      "         [ -0.1196,  -0.3092,  -0.4987],\n",
      "         [  2.3203,   2.6607,   3.0011],\n",
      "         [  0.0367,   0.1285,   0.2202],\n",
      "         [  2.9038,   3.6465,   4.3891],\n",
      "         [  3.0210,   3.7200,   4.4189],\n",
      "         [  2.4941,   2.9616,   3.4292],\n",
      "         [ -2.4617,  -3.1968,  -3.9320]],\n",
      "\n",
      "        [[ 12.9956,  14.0420,  15.0884],\n",
      "         [ 11.4176,  12.3456,  13.2735],\n",
      "         [ -9.6122, -10.3326, -11.0529],\n",
      "         [ -1.6359,  -1.8254,  -2.0149],\n",
      "         [  5.0438,   5.3842,   5.7246],\n",
      "         [  0.7708,   0.8625,   0.9543],\n",
      "         [  8.8450,   9.5876,  10.3303],\n",
      "         [  8.6126,   9.3116,  10.0106],\n",
      "         [  6.2343,   6.7019,   7.1694],\n",
      "         [ -8.3430,  -9.0782,  -9.8133]],\n",
      "\n",
      "        [[  8.8100,   9.8564,  10.9028],\n",
      "         [  7.7059,   8.6338,   9.5618],\n",
      "         [ -6.7308,  -7.4512,  -8.1715],\n",
      "         [ -0.8777,  -1.0673,  -1.2568],\n",
      "         [  3.6820,   4.0224,   4.3629],\n",
      "         [  0.4038,   0.4955,   0.5873],\n",
      "         [  5.8744,   6.6170,   7.3597],\n",
      "         [  5.8168,   6.5158,   7.2147],\n",
      "         [  4.3642,   4.8318,   5.2993],\n",
      "         [ -5.4023,  -6.1375,  -6.8727]],\n",
      "\n",
      "        [[ 29.7380,  30.7844,  31.8308],\n",
      "         [ 26.2647,  27.1926,  28.1205],\n",
      "         [-21.1378, -21.8582, -22.5785],\n",
      "         [ -4.6684,  -4.8579,  -5.0474],\n",
      "         [ 10.4907,  10.8312,  11.1716],\n",
      "         [  2.2389,   2.3306,   2.4224],\n",
      "         [ 20.7272,  21.4699,  22.2125],\n",
      "         [ 19.7959,  20.4949,  21.1938],\n",
      "         [ 13.7148,  14.1824,  14.6499],\n",
      "         [-20.1057, -20.8408, -21.5760]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([4, 1, 4])\n",
      "tensor([[[20., 21., 22., 23.]],\n",
      "\n",
      "        [[36., 37., 38., 39.]],\n",
      "\n",
      "        [[ 0.,  1.,  2.,  3.]],\n",
      "\n",
      "        [[24., 25., 26., 27.]]])\n",
      "torch.Size([4, 10, 3])\n",
      "tensor([[[ 21.3668,  22.4132,  23.4596],\n",
      "         [ 18.8411,  19.7691,  20.6970],\n",
      "         [-15.3750, -16.0954, -16.8157],\n",
      "         [ -3.1521,  -3.3417,  -3.5312],\n",
      "         [  7.7672,   8.1077,   8.4481],\n",
      "         [  1.5048,   1.5966,   1.6883],\n",
      "         [ 14.7861,  15.5287,  16.2714],\n",
      "         [ 14.2043,  14.9032,  15.6022],\n",
      "         [  9.9746,  10.4421,  10.9097],\n",
      "         [-14.2243, -14.9595, -15.6947]],\n",
      "\n",
      "        [[ 38.1092,  39.1556,  40.2020],\n",
      "         [ 33.6882,  34.6161,  35.5440],\n",
      "         [-26.9006, -27.6210, -28.3413],\n",
      "         [ -6.1846,  -6.3742,  -6.5637],\n",
      "         [ 13.2142,  13.5547,  13.8951],\n",
      "         [  2.9729,   3.0646,   3.1564],\n",
      "         [ 26.6684,  27.4110,  28.1537],\n",
      "         [ 25.3875,  26.0865,  26.7854],\n",
      "         [ 17.4551,  17.9226,  18.3901],\n",
      "         [-25.9870, -26.7222, -27.4573]],\n",
      "\n",
      "        [[  0.4389,   1.4852,   2.5316],\n",
      "         [  0.2824,   1.2103,   2.1382],\n",
      "         [ -0.9680,  -1.6884,  -2.4087],\n",
      "         [  0.6385,   0.4490,   0.2594],\n",
      "         [  0.9585,   1.2990,   1.6394],\n",
      "         [ -0.3303,  -0.2385,  -0.1468],\n",
      "         [ -0.0667,   0.6759,   1.4185],\n",
      "         [  0.2252,   0.9242,   1.6231],\n",
      "         [  0.6240,   1.0915,   1.5590],\n",
      "         [  0.4790,  -0.2562,  -0.9913]],\n",
      "\n",
      "        [[ 25.5524,  26.5988,  27.6452],\n",
      "         [ 22.5529,  23.4808,  24.4088],\n",
      "         [-18.2564, -18.9768, -19.6971],\n",
      "         [ -3.9103,  -4.0998,  -4.2893],\n",
      "         [  9.1290,   9.4694,   9.8099],\n",
      "         [  1.8718,   1.9636,   2.0553],\n",
      "         [ 17.7567,  18.4993,  19.2420],\n",
      "         [ 17.0001,  17.6990,  18.3980],\n",
      "         [ 11.8447,  12.3122,  12.7798],\n",
      "         [-17.1650, -17.9002, -18.6353]]], grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([2, 1, 4])\n",
      "tensor([[[16., 17., 18., 19.]],\n",
      "\n",
      "        [[32., 33., 34., 35.]]])\n",
      "torch.Size([2, 10, 3])\n",
      "tensor([[[ 17.1812,  18.2276,  19.2740],\n",
      "         [ 15.1294,  16.0573,  16.9853],\n",
      "         [-12.4936, -13.2140, -13.9343],\n",
      "         [ -2.3940,  -2.5835,  -2.7731],\n",
      "         [  6.4055,   6.7459,   7.0864],\n",
      "         [  1.1378,   1.2295,   1.3213],\n",
      "         [ 11.8155,  12.5582,  13.3008],\n",
      "         [ 11.4085,  12.1074,  12.8064],\n",
      "         [  8.1045,   8.5720,   9.0395],\n",
      "         [-11.2837, -12.0188, -12.7540]],\n",
      "\n",
      "        [[ 33.9236,  34.9700,  36.0164],\n",
      "         [ 29.9764,  30.9043,  31.8323],\n",
      "         [-24.0192, -24.7396, -25.4599],\n",
      "         [ -5.4265,  -5.6160,  -5.8056],\n",
      "         [ 11.8525,  12.1929,  12.5333],\n",
      "         [  2.6059,   2.6976,   2.7894],\n",
      "         [ 23.6978,  24.4405,  25.1831],\n",
      "         [ 22.5917,  23.2907,  23.9896],\n",
      "         [ 15.5850,  16.0525,  16.5200],\n",
      "         [-23.0463, -23.7815, -24.5167]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = nn.Conv1d(1, 10, 2)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "dl = DataLoader(dataset, batch_size=4, worker_init_fn=seed_worker, generator=g, shuffle=True)\n",
    "for i in range(2):\n",
    "    print(\"Epoch\", i)\n",
    "    for batch, label in dl:\n",
    "       print(batch.unsqueeze(1).shape)\n",
    "       print(batch.unsqueeze(1))\n",
    "       o = a(batch.unsqueeze(1))\n",
    "       print(o.shape)\n",
    "       print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data and the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/whole_sequence.fasta', 'r') as f:\n",
    "    seqs = list(SeqIO.parse(f, 'fasta'))\n",
    "seq = {s.id:str(s.seq) for s in seqs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(seq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EH1(72)': 'MLLPETRNLLDLMDAATRGGRPRLETLPHAVGRKAVDKMSEDGEADPPEVAEVANGGFAGPASEIRFRRYRPLGEAAGLLPTLIYYHGGGFVIGNIETHDSTCRRLANKSRCQVISIDYRLAPEHPFPAPIDDGIAAFRHIRDNAESFGADAARLAVGGDSAGGAMAAVVCQACRDAGETGPAFQMLIYPATDSSRESASRVAFAEGYFLSKALMDWFWEAYVPEDTDLTDLRLSPLLATDFTGLPPAFVLTAGYDPLRDEGRAYADRLIEAGIKTTYVNYPGTIHGFFSLTRFLSQGLKANDEAAAVMGAHFGT',\n",
       " 'EH2(71)': 'MGLQKLIVRTLMKLPESWILKLAGGTPVEIDGRTMDPRIQLLAAQGAKAPSMTSMSIEDARKSADEGLALLDAKPRRTVSILSRTIPGPAGDLHVRIYTPAGATGPLPGIVYYHMGGCVIGNLETCNTFCSILADDCRAIVVSVDYRLAPEHKFPAAMDDAVASFDWVSENAAALGIDPTRLGVGGDSAGGWLSAVVCQTRKAEGKTQPKAQLLIYPATDLDAKEGSMQSCAEIYPLTAEIMDWFMQQFLNSPEDAKDLKASPAHSEDLSGLAPALIMTAGFDVLRDQGEAYGNRLRDAGVPVTYRCYDSLSHAYTAFSGAVPAARQACEEIARDMARALG',\n",
       " 'EH3(69)': 'MPDTTSLNIADDVRMDPRLKAMLAAFPMMEQQTFQTREEQVANANTPEATAAREQLKMMMDMMDSEEFAPSDNLDISTREFTSSPDGNAIKIQFIRPKGKQKVPCVYYIHGGGMMIMSAFYGNYRAWGKMIANNGVAVAMVDFRNCLSPSSAPEVAPFPAGLNDCVSGLKWVSENADELSIDKNKIIIAGESGGGNLTLATGLKLKQDGNIDLVKGLYALCPYIAGKWPQDRFPSSSENNGIMIELHNNQGALAYGIEQLEAENPLAWPSFASAEDMQGLPPTVINVNECDPLRDEGIDFYRRLMAAGVPARCRQVMGTCHAGDMFVAVIPDVSADTAADIARTAKGG',\n",
       " 'CalB(68)': 'MALPSGSDPAFSQPKSVLDAGLTCQGASPSSVSKPILLVPGTGTTGPQSFDSNWIPLSTQLGYTPCWISPPPFMLNDTQVNTEYMVNAITALYAGSGNNKLPVLTWSQGGLVAQWGLTFFPSIRSKVDRLMAFAPDYKGTVLAGPLDALAVSAPSVWQQTTGSALTTALRNAGGLTQIVPTTNLYSATDEIVQPQVSNSPLDSSYLFNGKNVQAQAVCGPLFVIDHAGSLTSQFSYVVGRSALRSTTGQARSADYGITDCNPLPANDLTPEQKVAAAALLAPAAAAIVAGPKQNCEPDLMPYARPFAVGKRTCSGIVTPLE',\n",
       " 'EH4(67)': 'MSLQRMIVRTLLKLPDGLLVKMSGGKPLEIDGRTLDARVQLLASQGAKAPSMTTLPIEEARKGADDGLAMLDAKPRRNVSILSRSIPGPEGELHVRVYTPAGATGPLPGIVYYHMGGCVIGGLETCNTFCSILAEDCRAIVVSVDYRLAPEHKFPAAIDDAIASYDWVYQNATALGIDNTRLGLGGDSAGGWLSAVVCQHRKREGLPQPKAQLLIYPATDLQMTGGSMESCKDVYPLTREIMDWFMAQFLTSDADRSDWRGSPGQTADLSGLAPAIVATAGFDVLRDQGEAYANKLKAAGVPASYHCYDSLAHAFTAFSGTVPAAKQACEELAREMAKALNA',\n",
       " 'EH5(67)': 'MALNSQAEELLKRAAESGTPGLGEGTPEEGRAIFATTTQLLGLPAPDVKDTKEIQISGPNGPIRTLVITPDGVETNNLPLFIYYHGGGWVIGSPETHYEECCYYANEAQCIVLVPDYRLAPEYPFPAAPEDCYAVLQWAADNAESLGADKSRIAVGGDSAGGNLSAVVAQMTQQRNGPELALQLLIYPATRMGADTQSYKDFEDGYFLTAKAMNWFFGHYLKKAEDWDNLLASPLLNDDLAGLAPAYVVTAGFDPLRDEGRAYADKLKAAGVPVEYVCYEGQIHGFASMAGALDEARSFLDEAAKVLRKAFNK',\n",
       " 'EH6(66)': 'MPLHPQIEGLLQQMAAAGGKGFHQMEVDECRQTFGGLLNSLPPSQQKIASAQDRGIPSPNGPVKVRVYTPEGSGPFPVMAYFHGGGWVIGDLETHDSLCRELCGAVGMVVVSVDYRLAPEHKFPAAPDDCVAVTRWIAANAAALNADASRIAVGGDSAGGNLAAVVAQRLRDEDALKLAAQLLIYPVVHLDGVATPSMIENAEGYLLTRKDMEWFGGHYLASPADGQNASASPILAKSLAGLPPALVLTCEFDPLRDEGEKYGKALQAAGVPTTISRHDGTIHATFSFFTALEPGRRMADEAIRWLKEQLVK',\n",
       " 'EH7(64)': 'MEFPMAQSNIIAGMDLNRLDRIAEHLDRAYLHPGKLAGTMTLVARRGEVVYCQAQGLRDVERQLPVERDTLFRIYSMTKPITSIALMQLYEQGRFLLDEPVHKYIPTWKNLRVYKTGSHPQMLTTAPQRPMTIRDLLTHQSGLTYGFMNRTNVDAAYRSLKLDGGPGHTLDRLIDELARLPLEFSPGTAWNYSVATDVCGYLVQLLSGMSLDDYFSKHIFQPLGMPDTFFTVPAEKLSRFAACYEYQPGDSFSLQDDPQGSAFAKAHGYLSGGGGLVSCVDDYYRFAQALANGGELDGARIIGRKTLEFMRMNHLPDNKGLPDVAIGSFSETPYDGTGFGLGFSVKLDVAKSQTVGSVGEYGWGGMASTNFFIDPEEDLLMVFMTQLIPSSTYAVRQELRAIINGALVD',\n",
       " 'EH8(63)': 'MNPAVIERATVRALMSLPGPVLERLAAGLETHSRPHLDSRLRFLLALSGAKPTLDSGTVEQARQIYRSTLALLDMAPVSLPVVVDHQVSMEDGSQILVRRYRPADAPLVSPAIMFFHGGGFTIGGVEEYDRLCRYIAKRTNAVVLSVDYRLAPEHPAPAGMDDALEAWRWLLNNTAQLGLDPNRLAVMGDSAGGCMSAVVSQQAKLAGLALPALQVLIYPTTDAALAHPSVQTLGQGFGLDIPLLTWFRGHFVQDPAVIEDYRVSPLRNPDLTGLPEAIVITATDPLRDEGLEYAQKLREAGNTVTSLDYPELIHGFISMGGVVPAARKAINDICVETKRRL',\n",
       " 'EH9(61)': 'MEKKMALDKQAAEILKRAEESDTPGLGEGSPAEGREVFAGTTALLGLPTPEGQRISEVQIPGPSGDIRTRIIHPLEGLADNLPILIYYHGGGWVIGSPETHEGETCFYANEANCVVLVPDYRLAPEDPFPAAPDDCYAVLEWANANAETFGGDASRIAVAGDSAGGNLSAVVSQMAHANNGPDIALQLLIYPATRMGATTESYREFNDGYFLTGKAMDWFFNHYLKRPEDWDALKASPLLAPDLSGLPPAYIMTAGFDPLRDEGKAYAERLQQAGVPVDYVCYEEQIHGFVSMAGALDQGKQFLREAAAVLRRAFTS'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = islice(a, 10)\n",
    "dict(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the tokenizer and the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import (\n",
    "    accuracy, f1_score, precision, recall, auroc, average_precision, cohen_kappa, confusion_matrix, \n",
    "    matthews_corrcoef) \n",
    "from torchmetrics.functional.regression import (\n",
    "    mean_absolute_error, mean_squared_error,  pearson_corrcoef, kendall_rank_corrcoef, r2_score,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "low_cpu_mem_usage: when loading try not to use more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "                        load_in_4bit=True,\n",
    "                        bnb_4bit_use_double_quant=True,\n",
    "                        bnb_4bit_quant_type=\"nf4\",\n",
    "                        bnb_4bit_compute_dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 350])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", low_mem_usage=True)\n",
    "tok = tokenizer(list(seq.values())[:3], padding=True, truncation=True, return_tensors=\"pt\", is_split_into_words=False)\n",
    "tok[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#model.to(device)\n",
    "#model.eval()\n",
    "model_masked_16 = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, device_map=\"cpu\", torch_dtype=torch.float16)\n",
    "model_16 = AutoModelForSequenceClassification.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", device_map=\"cpu\", torch_dtype=torch.float16) \n",
    "# most models might not be able to do inference with float 16. Its errors is lower than bfloat16 but you cannot run it in CPUs maybe\n",
    "model_masked = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, device_map=\"cpu\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "state3 = model_16(**tok, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0303, -0.0179],\n",
       "        [-0.0428,  0.0095],\n",
       "        [-0.0320, -0.0229]], dtype=torch.float16, grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state3[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.softmax(state3[\"logits\"], dim=-1)\n",
    "target = torch.tensor([0, 1, 0])\n",
    "arg_pred = torch.argmax(pred, dim=-1)\n",
    "arg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4968, 0.5029],\n",
       "        [0.4868, 0.5132],\n",
       "        [0.4978, 0.5024]], dtype=torch.float16, grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(preds=pred, target=target, num_classes=2, task=\"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(preds=arg_pred, target=target, num_classes=2, task=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([113, 1280])\n"
     ]
    }
   ],
   "source": [
    "for x, num in enumerate(state3.hidden_states[-1]):\n",
    "    print(x, num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3842,  0.2355, -0.0170,  ..., -0.0648,  0.0435,  0.3384],\n",
       "         [-0.3330,  0.1190, -0.1903,  ...,  0.0394,  0.6241,  0.1100],\n",
       "         [ 0.0212,  0.1590,  0.2530,  ..., -0.6242, -0.3696, -0.0616],\n",
       "         ...,\n",
       "         [ 0.4657,  0.3142,  0.5557,  ..., -0.3871, -1.2033,  0.1668],\n",
       "         [ 0.6945,  0.1695,  0.3626,  ..., -0.0984, -0.4144,  0.3217],\n",
       "         [-0.6857,  0.2913,  1.1568,  ..., -0.8662, -0.8437, -0.0968]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state3.hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(state3.hidden_states[0].cpu().detach().numpy()).mean(axis=0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d631278fda44e4bb5e0151f5eabffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flax_model.msgpack:   0%|          | 0.00/4.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading a Flax model in PyTorch, requires both PyTorch and Flax to be installed. Please see https://pytorch.org/ and https://flax.readthedocs.io/en/latest/installation.html for installation instructions.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBioML\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m embeddings\n\u001b[1;32m----> 3\u001b[0m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/whole_sequence.fasta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mElnaggarLab/ankh-large-encoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Mi unidad\\BSC\\programs\\BioML\\BioML\\deep\\embeddings.py:290\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(fasta_file, model_name, disable_gpu, batch_size, save_path, option, format_, mode, dtype, **pretrained_args)\u001b[0m\n\u001b[0;32m    288\u001b[0m config \u001b[38;5;241m=\u001b[39m LLMConfig(model_name, disable_gpu\u001b[38;5;241m=\u001b[39mdisable_gpu, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    289\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m TokenizeFasta(config)\n\u001b[1;32m--> 290\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mExtractEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m tok \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(fasta_file)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# even if I have more columns in tok, it will only get the input_ids and the attention_mask\u001b[39;00m\n",
      "File \u001b[1;32m<string>:6\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, config, pretrained_args)\u001b[0m\n",
      "File \u001b[1;32mG:\\Mi unidad\\BSC\\programs\\BioML\\BioML\\deep\\embeddings.py:138\u001b[0m, in \u001b[0;36mExtractEmbeddings.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mesm2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_name:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_pooling_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_name, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device_map\u001b[38;5;241m=\u001b[39mdevice, \n\u001b[0;32m    139\u001b[0m                                        torch_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    140\u001b[0m                                        low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, offload_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffload\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_args)\n",
      "File \u001b[1;32mc:\\Users\\ruite\\miniforge3\\envs\\bioml\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    565\u001b[0m     )\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ruite\\miniforge3\\envs\\bioml\\lib\\site-packages\\transformers\\modeling_utils.py:3510\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3508\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m from_flax:\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3510\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_flax_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_flax_checkpoint_in_pytorch_model\n\u001b[0;32m   3512\u001b[0m         model \u001b[38;5;241m=\u001b[39m load_flax_checkpoint_in_pytorch_model(model, resolved_archive_file)\n\u001b[0;32m   3513\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ruite\\miniforge3\\envs\\bioml\\lib\\site-packages\\transformers\\modeling_flax_pytorch_utils.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnpicklingError\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Tuple\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "from BioML.deep import embeddings\n",
    "\n",
    "embeddings.generate_embeddings('../data/whole_sequence.fasta', model_name=\"ElnaggarLab/ankh-large-encoder\", option=\"mean\", save_path=\"embeddings.csv\", \n",
    "                               mode=\"write\", batch_size=1, from_flax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_8 = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=1.0)\n",
    "model_8bit = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, device_map=\"cuda\", quantization_config=quant_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=30, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100000.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(100_000, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf, dtype=torch.float16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(100_000, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(99840., dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(100_000, dtype=torch.bfloat16) \n",
    "# los numeros que puede presentar antes de que sea 0 y la precision que puede presentar es diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, device_map=\"auto\", \n",
    "                                  quantization_config=None)\n",
    "\n",
    "#output.logits# logits es lo que le das al softmax para que lo convierta en probabilidad -> softmax(logits) es el output the last linear model\n",
    "# y que es last hidden state entonces? Es muy diferente a los logits? El shape es diferente -> para cada position devuelve la probabilidad de que sea uno de los tokens\n",
    "# EL maskedLM y el automodel hidden state es lo mismo -> pero la logits cambia. Cual debería usar para el embedding?\n",
    "#output.hidden_states[-1] # en el caso de MASkedLM si no le especifico de devolver hidden states, no los devuelve, pero en el caso de automodel si los devuelve aun sin lo del hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HqqConfig' from 'transformers' (/home/ruite/miniconda3/envs/bioml_pycaret/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, HqqConfig\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Method 1: all linear layers will use the same quantization config\u001b[39;00m\n\u001b[1;32m      4\u001b[0m quant_config  \u001b[38;5;241m=\u001b[39m HqqConfig(nbits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, group_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, quant_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, quant_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m#axis=0 is used by default\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HqqConfig' from 'transformers' (/home/ruite/miniconda3/envs/bioml_pycaret/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HqqConfig\n",
    "\n",
    "# Method 1: all linear layers will use the same quantization config\n",
    "quant_config  = HqqConfig(nbits=8, group_size=64, quant_zero=False, quant_scale=False, axis=0) #axis=0 is used by default\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"cuda\", \n",
    "    quantization_config=quant_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No GPU found. A GPU is needed for quantization.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the threshold determines the values that are considered outliers and are calculated using 16 bit precision\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# the smaller it is the less memory it will save because, at the eveyrhting will be calculated with 16 bits\u001b[39;00m\n\u001b[1;32m      7\u001b[0m quant_8 \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, llm_int8_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m) \n\u001b[0;32m----> 8\u001b[0m model_8bit \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/esm2_t6_8M_UR50D\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_pooling_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtok) \u001b[38;5;66;03m# full 32 precision\u001b[39;00m\n\u001b[1;32m     11\u001b[0m output_16 \u001b[38;5;241m=\u001b[39m model_16(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtok) \u001b[38;5;66;03m# half 16 precision\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bioml_pycaret/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/bioml_pycaret/lib/python3.10/site-packages/transformers/modeling_utils.py:2897\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[1;32m   2896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m-> 2897\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo GPU found. A GPU is needed for quantization.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[1;32m   2899\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2900\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `pip install bitsandbytes`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2903\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No GPU found. A GPU is needed for quantization."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoModelForMaskedLM, BitsAndBytesConfig\n",
    "\n",
    "model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, device_map=\"cpu\")\n",
    "model_16 = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, device_map=\"cpu\",  torch_dtype=torch.float16) \n",
    "# the threshold determines the values that are considered outliers and are calculated using 16 bit precision\n",
    "# the smaller it is the less memory it will save because, at the eveyrhting will be calculated with 16 bits\n",
    "quant_8 = BitsAndBytesConfig(load_in_8bit=True, llm_int8_threshold=1.0) \n",
    "model_8bit = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", add_pooling_layer=False, device_map=\"cuda\", \n",
    "                                       quantization_config=quant_8)\n",
    "output = model(**tok) # full 32 precision\n",
    "output_16 = model_16(**tok) # half 16 precision\n",
    "output_8 = model_8bit(**tok) # quatized to 8 bits\n",
    "data = {32: output.last_hidden_state, 16: output_16.last_hidden_state, 8: output_8.last_hidden_state}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([343, 320])\n",
      "torch.Size([343, 320])\n"
     ]
    }
   ],
   "source": [
    "for num, x in enumerate(output.last_hidden_state):\n",
    "    print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([343, 320])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(x, start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of max: 0.0029924903 mean: 0.00063062285\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of max:\", (data[32] - data[16]).abs().max(axis=1)[0].mean().detach().numpy(), \"mean:\", \n",
    "      (data[32] - data[16]).abs().mean().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of max: 0.053529274 mean: 0.012010117\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of max:\", (data[32] - data[8]).abs().max(axis=1)[0].mean().detach().numpy(), \"mean:\", \n",
    "      (data[32] - data[8]).abs().mean().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_masked(**tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 343, 33])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft = F.softmax(output.logits, dim=-1).detach()\n",
    "soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 336, 316, 336, 258, 145, 163, 114, 161, 124, 120,  98, 115, 256,\n",
       "         123, 212, 185, 144, 127, 119,   1, 286, 140, 103, 165, 165, 165, 165,\n",
       "         165, 165, 165, 165, 336],\n",
       "        [  0, 281, 342, 281, 269, 172, 190, 144, 188, 151, 181, 219,  97, 283,\n",
       "         150, 153, 212, 171, 154, 146,   1, 313, 167, 130, 192, 222, 192, 192,\n",
       "         192, 192, 192, 192, 281]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(soft, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max difference: 0.01247859\n",
      "mean difference: 0.00063062285\n"
     ]
    }
   ],
   "source": [
    "model_masked_16 = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, \n",
    "                                                       device_map=\"cpu\", torch_dtype=torch.float16)\n",
    "\n",
    "model_masked = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", output_hidden_states=True, \n",
    "                                                    device_map=\"cpu\", torch_dtype=torch.float32)\n",
    "\n",
    "output = model_masked(**tok)\n",
    "output_16 = model_masked_16(**tok)\n",
    "\n",
    "print(\"max difference:\", (output.hidden_states[-1] - output_16.hidden_states[-1]).max().detach().numpy())\n",
    "print(\"mean difference:\", (output.hidden_states[-1] - output_16.hidden_states[-1]).abs().mean().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 343, 320])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**tok)\n",
    "output # si no le especificas hidden states -> tampoco tiene hidden states, sino que tiene last_hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1421,  0.5840, -0.0724,  ...,  1.1748, -0.0931, -0.4209],\n",
       "         [ 0.4133,  0.0937, -0.1658,  ...,  0.8398, -0.2219, -0.2437],\n",
       "         [ 0.0767, -0.5088, -0.0298,  ...,  0.3887, -0.0302,  0.1070],\n",
       "         ...,\n",
       "         [-0.2573,  0.2483,  0.5522,  ...,  0.6455, -0.5259, -0.0944],\n",
       "         [-0.3516,  0.2590,  0.5864,  ...,  0.4985, -0.5669, -0.1550],\n",
       "         [-0.3301,  0.2368,  0.2407,  ...,  0.4675, -0.6846, -0.3098]],\n",
       "\n",
       "        [[ 0.0927,  0.6987, -0.0489,  ...,  1.0352, -0.1703, -0.3040],\n",
       "         [ 0.3230,  0.4792, -0.1464,  ...,  0.7700, -0.2129, -0.2917],\n",
       "         [ 0.0061, -0.2739,  0.2622,  ..., -0.0435,  0.2888,  0.1104],\n",
       "         ...,\n",
       "         [-0.4729, -0.2120, -0.2720,  ...,  0.9448, -0.3599,  0.2312],\n",
       "         [-0.0944, -0.4836,  0.0655,  ...,  0.3899, -0.1250, -0.1101],\n",
       "         [-0.0054,  0.0670,  0.1100,  ...,  0.6562, -0.6016, -0.2551]]],\n",
       "       dtype=torch.float16, grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_16 = model_16(**tok)\n",
    "output_16.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.483202"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_float16.get_memory_footprint()/1e+6\n",
    "#model.get_memory_footprint()/1e+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_16 = output.last_hidden_state - output_16.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0125, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_16.max(axis=1).values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 15.0938,  -7.5859,  -6.3984,  ..., -15.4062, -15.6328,  -7.5781],\n",
       "         [ -9.7422, -16.4844,  -9.3047,  ..., -15.8906, -16.1406, -16.4688],\n",
       "         [-11.9688, -21.8438, -12.3438,  ..., -15.7969, -15.8750, -21.8281],\n",
       "         ...,\n",
       "         [ -5.5430,  -6.7969,  14.7812,  ..., -16.7656, -16.5781,  -6.8281],\n",
       "         [ -5.4414,  -6.3516,  17.0000,  ..., -16.7031, -16.5156,  -6.3867],\n",
       "         [ -5.4102,  -6.6562,  16.5625,  ..., -16.6719, -16.4844,  -6.6953]],\n",
       "\n",
       "        [[ 16.1562,  -5.9922,  -6.4141,  ..., -15.2656, -15.4844,  -5.9805],\n",
       "         [ -9.0000, -15.7500,  -7.1562,  ..., -15.9609, -16.2344, -15.7500],\n",
       "         [-11.6250, -19.8281, -10.8594,  ..., -15.8203, -15.9297, -19.8125],\n",
       "         ...,\n",
       "         [-10.2578, -20.8750, -12.7188,  ..., -15.9688, -16.0312, -20.9062],\n",
       "         [-12.6641, -21.1250, -12.9375,  ..., -16.2031, -16.3438, -21.1094],\n",
       "         [ -6.0078,  -5.7773,  17.8594,  ..., -16.7188, -16.5938,  -5.8281]]],\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_8bit = model_8bit(**tok)\n",
    "output_8bit.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = output.logits - output_8bit.logits\n",
    "state = output.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4023, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference[0,:,-11].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7880e-05, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([343, 160])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.AvgPool1d(2)(output.last_hidden_state[-1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the attention mask to remove the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "mask = tok[\"attention_mask\"].bool()\n",
    "for num, x in enumerate(output.last_hidden_state):\n",
    "    masked_x = x[mask[num]]\n",
    "    results[num] = masked_x.mean(dim=0).detach().cpu().numpy()\n",
    "    # detach removes the tensor from the computation graph (the gradient won't be computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(results[0], dim=0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data2.csv\"\n",
    "embeddings = pd.DataFrame(results).T\n",
    "embeddings.to_csv(path, mode='a', header=not Path(path).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([343, 320])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[tok[\"attention_mask\"].bool()[1]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt the code to Load large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "# https://huggingface.co/docs/datasets/loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to load files within datasets -> from local or remote files (in these formats json, csv, text, parquet)  \n",
    "Since we have a fasta file that is not supported (because it will treat each line as a row so it will double the rows, but in fasta the first line is an id).  \n",
    "So we can process it in-memory to pandas, generators, dictionaries or list of dictionaries and use Datasets instead of load_dataset.  \n",
    "The load dataset returns a dataset dict with different splits (train, test, val) as keys and then a dataset object as values.\n",
    "\n",
    "But we are using a dataset object directl\n",
    "\n",
    "To load fasta files use from generator beacause it is in-memory and the file might be too large to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 294\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = load_dataset(\"text\", data_files=\"../data/whole_sequence.fasta\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_generator(fasta_file: str=\"../data/whole_sequence.fasta\"):\n",
    "    with open(fasta_file, 'r') as f:\n",
    "        seqs = SeqIO.parse(f, 'fasta')\n",
    "        for seq in seqs:\n",
    "            yield {\"id\":seq.id, \"seq\":str(seq.seq)}\n",
    "\n",
    "with open(\"../data/whole_sequence.fasta\", 'r') as f:\n",
    "    seqs = SeqIO.parse(f, 'fasta')\n",
    "    d = pd.Series({s.id:str(s.seq) for s in seqs}).to_frame()\n",
    "    d.columns = [\"sequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'seq'],\n",
       "    num_rows: 147\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Dataset.from_generator(fasta_generator, gen_kwargs={\"fasta_file\":\"../data/whole_sequence.fasta\"})\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process or tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use map to apply the tokenizer function to the entire dataset\n",
    "The map will create and add the new columns ('input_ids', 'attention_mask') coming from the tokenizer to the datatset   \n",
    "but you will have to change its format to torch tensors for the models to read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = b.map(lambda examples: tokenizer(examples[\"seq\"], return_tensors=\"pt\",padding=True, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = dataset.select_columns([\"id\",\"input_ids\", \"attention_mask\"])\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'seq', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 147\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to extract the embeddings use the dataloader from pytorch to create the batches for you  \n",
    "It will only return the input_ids and the attention mask (the ids are lost, so yoou don't know which sequence is which)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 20, 10,  ...,  1,  1,  1],\n",
       "        [ 0, 20, 15,  ...,  1,  1,  1],\n",
       "        [ 0, 20, 15,  ...,  1,  1,  1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4)\n",
    "for batch in dataloader:\n",
    "    u = batch\n",
    "u[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BioML.deep.embeddings as emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f39e453b894286bd6382344628cda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = emb.TokenizeFasta(emb.LLMConfig()).tokenize(\"../data/whole_sequence.fasta\")\n",
    "embed = emb.ExtractEmbeddings(emb.LLMConfig())\n",
    "seq_keys = list(data[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, batch in enumerate(DataLoader(data, batch_size=batch_size)):\n",
    "    batch_seq_keys = seq_keys[num*batch_size:(num+1)*batch_size]\n",
    "    results = embed.extract(batch_seq_keys, batch)\n",
    "    #embed.save(results, \"../data/embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(\"../data/embeddings.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways to create emebeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = torch.nn.Linear(320, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mattention_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m attention_weights\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "attention_scores = attention_weights(output.hidden_states[-1])\n",
    "attention_weights = torch.softmax(attention_scores, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 343, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 109760])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp = output.hidden_states[-1].reshape(output.hidden_states[-1].shape[0], -1)\n",
    "_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1419,  0.5839, -0.0722,  ...,  0.4682, -0.6849, -0.3094],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, -107712)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0, 2048 - _temp.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.nn.functional.pad(_temp, (0, 2048 - _temp.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1419,  0.5839, -0.0722,  0.3390, -0.1853, -0.0982, -0.9235,  0.1019,\n",
       "        -0.4527, -0.6959], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109670"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(o[0].detach().numpy()).intersection(_temp[0].detach().numpy()))xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(output.hidden_states[-1][0][0].detach().numpy()).intersection(_temp[0][:100].detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test training using the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BioML.models.regression as regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(\"../data/embeddings.csv\", index_col=0)\n",
    "label = list(range(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-02-2024 12:07:16 INFO ------------------------------------------------------------------------------\n",
      "23-02-2024 12:07:16 INFO PycaretInterface parameters\n",
      "23-02-2024 12:07:16 INFO Seed: 200\n",
      "23-02-2024 12:07:16 INFO Budget time: 20\n",
      "23-02-2024 12:07:16 INFO The number of models to select: 3\n",
      "23-02-2024 12:07:16 INFO Output path: regression_training\n",
      "23-02-2024 12:07:16 INFO ----------------Trainer inputs-------------------------\n",
      "23-02-2024 12:07:16 INFO Number of kfolds: 5\n",
      "23-02-2024 12:07:16 INFO Number of iterations: 30\n"
     ]
    }
   ],
   "source": [
    "data = regression.DataParser(\"../data/embeddings.csv\", label)\n",
    "experiment = regression.PycaretInterface(\"regression\", 200, scaler= \"zscore\", budget_time=20, best_model=3, \n",
    "                                        output_path=\"regression_training\", optimize=\"RMSE\")\n",
    "\n",
    "regressor = regression.Regressor(test_size=0.2, optimize=\"RMSE\")\n",
    "training = regression.Trainer(experiment, regressor, 5, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data according to sequence similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = regression.split.ClusterSpliter(\"../data/resultsDB_clu.tsv\", 5, random_state=experiment.seed, test_size=0.2)\n",
    "X_train, X_test = c.train_test_split(data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/23 12:18:52 INFO mlflow.tracking.fluent: Experiment with name 'Regression' does not exist. Creating a new experiment.\n",
      "23-02-2024 12:18:53 INFO --------------------------------------------------------\n",
      "23-02-2024 12:18:53 INFO Training regression models\n",
      "23-02-2024 12:18:53 INFO The models used ['lr', 'lasso', 'ridge', 'en', 'lar', 'llar', 'omp', 'br', 'par', 'huber', 'svm', 'knn', 'dt', 'rf', 'et', 'gbr', 'mlp', 'xgboost', 'catboost', 'dummy']\n",
      "23-02-2024 12:18:53 INFO Time budget is 20 minutes\n",
      "23-02-2024 12:20:27 INFO Training over: Total runtime 1.565 minutes\n",
      "23-02-2024 12:20:27 INFO Analyse the best models and plotting them\n",
      "23-02-2024 12:20:27 INFO Analyse the top 1 model: catboost\n",
      "23-02-2024 12:24:10 INFO Analyse the top 2 model: br\n",
      "23-02-2024 12:24:13 INFO Analyse the top 3 model: rf\n",
      "23-02-2024 12:24:27 INFO --------Stacking the best models--------\n",
      "23-02-2024 12:24:27 INFO ----------Stacking the best models--------------\n",
      "23-02-2024 12:27:58 INFO --------Creating an ensemble model--------\n",
      "23-02-2024 12:27:58 INFO ----------Creating a majority voting model--------------\n",
      "23-02-2024 12:27:58 INFO fold: 5\n",
      "23-02-2024 12:27:58 INFO weights: None\n",
      "23-02-2024 12:28:45 INFO --------Retuning the best models--------\n",
      "23-02-2024 12:28:45 INFO Retuning catboost\n",
      "23-02-2024 12:28:45 INFO ---------Retuning the best models--------------\n",
      "23-02-2024 12:28:45 INFO num_iter: 30\n",
      "23-02-2024 12:28:45 INFO fold: 5\n",
      "23-02-2024 12:45:00 INFO Retuning br\n",
      "23-02-2024 12:45:00 INFO ---------Retuning the best models--------------\n",
      "23-02-2024 12:45:00 INFO num_iter: 30\n",
      "23-02-2024 12:45:00 INFO fold: 5\n",
      "23-02-2024 12:45:16 INFO Retuning rf\n",
      "23-02-2024 12:45:16 INFO ---------Retuning the best models--------------\n",
      "23-02-2024 12:45:16 INFO num_iter: 30\n",
      "23-02-2024 12:45:16 INFO fold: 5\n",
      "23-02-2024 12:46:25 INFO --------Stacking the best models--------\n",
      "23-02-2024 12:46:25 INFO ----------Stacking the best models--------------\n",
      "23-02-2024 12:46:44 INFO --------Creating an ensemble model--------\n",
      "23-02-2024 12:46:44 INFO ----------Creating a majority voting model--------------\n",
      "23-02-2024 12:46:44 INFO fold: 5\n",
      "23-02-2024 12:46:44 INFO weights: None\n"
     ]
    }
   ],
   "source": [
    "results, models_dict = training.generate_training_results(X_train, data.label, True,\n",
    "                                                          test_data=X_test, fold_strategy=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioml_pycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
