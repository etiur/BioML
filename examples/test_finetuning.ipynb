{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to finetune HuggingFace models on text data of any size and format with custom splitting (not random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to handle text data of any size and format with custom split because random splitting is not recommended for protein sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SeqIO\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBioML\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_methods\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m## https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from datasets import Dataset, DatasetDict\n",
    "from BioML.utilities import split_methods\n",
    "from BioML.deep.embeddings import LLMConfig, TokenizeFasta\n",
    "from BioML.utilities.utils import set_seed\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "## https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb\n",
    "## https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to label the target values as labels so Trainer can recognize it.\n",
    "Dataset can actually be used for any usecases with large   files it doesn't depend on transformers  \n",
    "Although you would need to use PyTorch Dataloader to transform it into batches (but it only returns inputs ids and attention masks will it also return labels?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_generator(fasta_file: str=\"../data/whole_sequence.fasta\"):\n",
    "    with open(fasta_file, 'r') as f:\n",
    "        seqs = SeqIO.parse(f, 'fasta')\n",
    "        for seq in seqs:\n",
    "            yield {\"id\":seq.id, \"seq\":str(seq.seq)}\n",
    "\n",
    "b = Dataset.from_generator(fasta_generator, gen_kwargs={\"fasta_file\":\"../data/whole_sequence.fasta\"})\n",
    "y = np.random.randint(0, 2, size=len(b))\n",
    "dataset = b.add_column(\"labels\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = TokenizeFasta()\n",
    "tokens = tok.tokenize(\"../data/whole_sequence.fasta\", ([\"labels\", y],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom spliting with indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = split_methods.ClusterSpliter(\"../data/resultsDB_clu.tsv\")\n",
    "train, test = cluster.train_test_split(range(len(dataset)), index=dataset[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(range(len(dataset)), stratify=dataset[\"labels\"], test_size=0.2) # random splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = DatasetDict({\"train\":dataset.select(train), \"test\":dataset.select(test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_, validation = cluster.train_test_split(range(len(new[\"train\"])), index=new[\"train\"][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_2 = DatasetDict({\"train\":new[\"train\"].select(train_), \"test\":dataset.select(test), \"validation\": new[\"train\"].select(validation)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the protein language models model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def model_init(): # 0 or 1 parameters ( the trial hyperparameters)\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", num_labels=2) # torch_dtype=torch.bfloat16 to load in bfloat16 which is accepted by CPUs unlike float16\n",
    "\n",
    "def model_init2(): # 0 or 1 parameters ( the trial hyperparameters)\n",
    "\treturn AutoModelForSequenceClassification.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", low_cpu_mem_usage=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", num_labels=2, low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692e5132e1a94a789f520755357e8eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f023ba77915497eb0fa9d8e070acf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new[\"train\"] = new[\"train\"].map(lambda examples: tokenizer(examples[\"seq\"], return_tensors=\"np\",padding=True, truncation=True), batched=True)\n",
    "new[\"test\"] = new[\"test\"].map(lambda examples: tokenizer(examples[\"seq\"], return_tensors=\"np\",padding=True, truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 8e-5\n",
    "bs = 1\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se use cpu to False whe you wan to use GPUs (it will automatically use GPUs), when f16 is True it will only use GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.2, lr_scheduler_type='cosine', fp16=False if device==\"cpu\" else True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to=['mlflow'],\n",
    "    load_best_model_at_end=True, metric_for_best_model=\"matthews_correlation\", \n",
    "    save_total_limit=2, save_strategy=\"epoch\", seed=3242342, gradient_accumulation_steps=4, use_cpu=True if device==\"cpu\" else False) \n",
    "\n",
    "## The warmup step together with cosine learning rate scheduler turns to onecycle learning rate scheduler\n",
    "## weight decay for the Adam (AdamW) -> this is fast.Ai does\n",
    "## fp16 is half precision -> mixed training (using fp32 and fp16)\n",
    "## save_total_limit to 3 -> so only 3 models will be saved\n",
    "## each 500 steps will be saved a model\n",
    "## Save the report to mlflow\n",
    "# How to evaluate mlflow?\n",
    "# LR finder does not give reliable results for Transformers models https://github.com/huggingface/transformers/issues/16013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model using several evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use your own function as an evaluation metric -> then you have to retun as an dict  \n",
    "Or you can use the evaluate library from hugging face to load different functions: [evaluate](https://huggingface.co/docs/evaluate/a_quick_tour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_metrics(eval_pred):\n",
    "    metrics = [\"accuracy\", \"f1\", \"matthews_correlation\", \"precision\", \"recall\"]\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    loaded = {metric:evaluate.load(metric) for metric in metrics}\n",
    "    results = {metric: loaded[metric].compute(predictions=predictions, references=labels)[metric] \n",
    "               for metric in metrics}\n",
    "\n",
    "    # the predictions from the models are logits (it also returns the labels, \n",
    "    # it also returns loss, attentions and hidden state but that is the classification model, for evalaution Trainer will only \n",
    "    # return logits and labels)\n",
    "    return results\n",
    "\n",
    "def compute_regression_metrics(eval_pred):\n",
    "\tmetrics = [\"mse\", \"mae\"]\n",
    "\tlogits, labels = eval_pred\n",
    "\tpredictions = logits\n",
    "\tloaded = {metric:evaluate.load(metric) for metric in metrics}\n",
    "\tresults = {metric: loaded[metric].compute(predictions=predictions, references=labels)[metric] \n",
    "\t\t\t   for metric in metrics}\n",
    "\tresults[\"r2\"] = evaluate.load(\"r_squared\").compute(predictions=predictions, references=labels)\n",
    "\tresults[\"rmse\"] = loaded[\"mse\"].compute(predictions=predictions, references=labels, squared=False)[\"mse\"]\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        print(inputs)\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = self.compute_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruite\\miniforge3\\envs\\bioml\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, args, train_dataset=new['train'], eval_dataset=new['test'], # we need to pass tokenized datasets\n",
    "                  tokenizer=tokenizer, compute_metrics=compute_classification_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameters learning rate and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-2, log=True),\n",
    "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [2, 4, 8, 16]),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_classification_objective(metrics: dict[str, float]) -> tuple[float, float]:\n",
    "\treturn metrics[\"eval_loss\"], metrics[\"eval_matthews_correlation\"]\n",
    "\n",
    "def compute_regression_objective(metrics: dict[str, float]) -> tuple[float, float]:\n",
    "\treturn metrics[\"eval_loss\"], metrics[\"eval_r2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "model_init should have 0 or 1 argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# we need to pass tokenized datasets\u001b[39;49;00m\n\u001b[0;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_classification_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStoppingCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ruite\\miniforge3\\envs\\bioml\\lib\\site-packages\\transformers\\trainer.py:389\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init \u001b[38;5;241m=\u001b[39m model_init\n\u001b[1;32m--> 389\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer` requires either a `model` or `model_init` argument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ruite\\miniforge3\\envs\\bioml\\lib\\site-packages\\transformers\\trainer.py:1457\u001b[0m, in \u001b[0;36mTrainer.call_model_init\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init(trial)\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_init should have 0 or 1 argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_init should not return None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: model_init should have 0 or 1 argument."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(None, args, model_init=model_init2, train_dataset=new['train'], eval_dataset=new['test'], # we need to pass tokenized datasets\n",
    "                  tokenizer=tokenizer, \n",
    "                  compute_metrics=compute_classification_metrics, \n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-05 18:27:53,211] A new study created in RDB with name: no-name-305c8b7d-b552-4cd6-b1d9-2e327a424486\n",
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bff178a0fc74c9b9ffc182ef25172a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fd50fa88104f34832ff3bb22d0fcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruite\\miniforge3\\envs\\bioml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6917587518692017, 'eval_accuracy': 0.5666666666666667, 'eval_f1': 0.0, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 18.5898, 'eval_samples_per_second': 1.614, 'eval_steps_per_second': 0.807, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ddca6ef5484552b6fbd08fc014c515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7241240739822388, 'eval_accuracy': 0.5, 'eval_f1': 0.4444444444444444, 'eval_matthews_correlation': -0.008988968316207744, 'eval_precision': 0.42857142857142855, 'eval_recall': 0.46153846153846156, 'eval_runtime': 17.8967, 'eval_samples_per_second': 1.676, 'eval_steps_per_second': 0.838, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d8f83bc982433cbba6a578c3844d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7805582880973816, 'eval_accuracy': 0.5, 'eval_f1': 0.4444444444444444, 'eval_matthews_correlation': -0.008988968316207744, 'eval_precision': 0.42857142857142855, 'eval_recall': 0.46153846153846156, 'eval_runtime': 18.3333, 'eval_samples_per_second': 1.636, 'eval_steps_per_second': 0.818, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-05 18:36:15,996] Trial 0 finished with values: [0.7805582880973816, -0.008988968316207744] and parameters: {'learning_rate': 7.813286994811102e-05, 'gradient_accumulation_steps': 4}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 501.8248, 'train_samples_per_second': 0.933, 'train_steps_per_second': 0.231, 'train_loss': 0.6711522244859016, 'epoch': 2.97}\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "best_trials = trainer.hyperparameter_search(\n",
    "\tdirection=[\"minimize\", \"maximize\"],\n",
    "\tbackend=\"optuna\",\n",
    "\thp_space=optuna_hp_space,\n",
    "\tn_trials=1,\n",
    "\tcompute_objective=compute_classification_objective,\n",
    "    storage='sqlite:///my_optuna_studies.db',\n",
    "    load_if_exists=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.args.learning_rate = best_trials[0].hyperparameters[\"learning_rate\"]\n",
    "trainer.args.gradient_accumulation_steps = best_trials[0].hyperparameters[\"gradient_accumulation_steps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3914d1c5b36242109903c985c86c6faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29f5a46314b493cb66386ad59cc7861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7221236824989319, 'eval_accuracy': 0.5333333333333333, 'eval_f1': 0.6956521739130436, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.5333333333333333, 'eval_recall': 1.0, 'eval_runtime': 31.508, 'eval_samples_per_second': 0.952, 'eval_steps_per_second': 0.476, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e19a75be81b47138b51a3809d41f9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7303746938705444, 'eval_accuracy': 0.5333333333333333, 'eval_f1': 0.6956521739130436, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.5333333333333333, 'eval_recall': 1.0, 'eval_runtime': 31.2142, 'eval_samples_per_second': 0.961, 'eval_steps_per_second': 0.481, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b5477268b8416aae340e6bca02f7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7445932030677795, 'eval_accuracy': 0.5333333333333333, 'eval_f1': 0.6956521739130436, 'eval_matthews_correlation': 0.0, 'eval_precision': 0.5333333333333333, 'eval_recall': 1.0, 'eval_runtime': 31.2265, 'eval_samples_per_second': 0.961, 'eval_steps_per_second': 0.48, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b70848b104408281ab0169afb06ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.753971517086029, 'eval_accuracy': 0.6, 'eval_f1': 0.7272727272727273, 'eval_matthews_correlation': 0.2857142857142857, 'eval_precision': 0.5714285714285714, 'eval_recall': 1.0, 'eval_runtime': 31.5365, 'eval_samples_per_second': 0.951, 'eval_steps_per_second': 0.476, 'epoch': 3.97}\n",
      "{'train_runtime': 618.7594, 'train_samples_per_second': 0.756, 'train_steps_per_second': 0.187, 'train_loss': 0.6006371070598734, 'epoch': 3.97}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=116, training_loss=0.6006371070598734, metrics={'train_runtime': 618.7594, 'train_samples_per_second': 0.756, 'train_steps_per_second': 0.187, 'train_loss': 0.6006371070598734, 'epoch': 3.97})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure that we get the same results by evaluating the results once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for hyperparameters like the learning rate which is the most important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it is actually batch size and learning rate -> smaller batch sizes tend to work better than large batch sizes -> but learning rate is affected by batch as well -> higher abtch need higher learning rate.\n",
    "\n",
    "Fix everything else and tune the learning rate -> learning rate finder doesn'0t seem to work very well for transformers?  \n",
    "But teh idea of learning rate finder is just test different learning rates -> so I cannot test them?\n",
    "\n",
    "Ktrains: A wrapper to do many tasks and has a learning rate finder: [ktrains](https://github.com/amaiya/ktrain)\n",
    "\n",
    "Use pytorch lightning perhaps: [pytorch_lighningt_huggingface](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"bigscience/T0pp\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter efficient fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_values = (16, 32, 64, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1, \n",
    "                         target_modules=[\"query\", \"value\", \"key\", \"output.dense\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_model.model.esm.encoder.layer.0.attention',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.query.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.key.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.value.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.dropout',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.self.rotary_embeddings',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dense.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.output.dropout',\n",
       " 'base_model.model.esm.encoder.layer.0.attention.LayerNorm',\n",
       " 'base_model.model.esm.encoder.layer.1.attention',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.query.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.key.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.value.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.dropout',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.self.rotary_embeddings',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dense.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.output.dropout',\n",
       " 'base_model.model.esm.encoder.layer.1.attention.LayerNorm',\n",
       " 'base_model.model.esm.encoder.layer.2.attention',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.query.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.key.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.value.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.dropout',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.self.rotary_embeddings',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dense.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.output.dropout',\n",
       " 'base_model.model.esm.encoder.layer.2.attention.LayerNorm',\n",
       " 'base_model.model.esm.encoder.layer.3.attention',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.query.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.key.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.value.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.dropout',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.self.rotary_embeddings',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dense.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.output.dropout',\n",
       " 'base_model.model.esm.encoder.layer.3.attention.LayerNorm',\n",
       " 'base_model.model.esm.encoder.layer.4.attention',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.query.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.key.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.value.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.dropout',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.self.rotary_embeddings',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dense.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.output.dropout',\n",
       " 'base_model.model.esm.encoder.layer.4.attention.LayerNorm',\n",
       " 'base_model.model.esm.encoder.layer.5.attention',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.query.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.key.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.value.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.dropout',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.self.rotary_embeddings',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.base_layer',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_dropout',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_dropout.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_A.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_B.default',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_embedding_A',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dense.lora_embedding_B',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.output.dropout',\n",
       " 'base_model.model.esm.encoder.layer.5.attention.LayerNorm']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target_module_names_for_peft(model, filter_=\"attention\"):\n",
    "    if isinstance(filter_, str):\n",
    "        filter_ = [filter_] # if it is a string, convert it to a list\n",
    "    module_names = []\n",
    "    for name, module in model.named_modules():\n",
    "        n = name.split(\".\")\n",
    "        if filter_ and set(n).intersection(filter_):\n",
    "            module_names.append(name)\n",
    "        elif not filter_:\n",
    "            module_names.append(name)\n",
    "    return module_names\n",
    "\n",
    "get_target_module_names_for_peft(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 199,680 || all params: 8,040,443 || trainable%: 2.483445252954346\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lora_model(model, rank: int, target_modules: str | list[str], \n",
    "                    lora_alpha: int | None=None):\n",
    "    \n",
    "    if lora_alpha is None:\n",
    "        lora_alpha = rank * 2\n",
    "    else:\n",
    "        print(\"Warning lora_alpha is set to a value. For optimal performance, it is recommended to set it double the rank\")\n",
    "    \n",
    "    # get the lora models\n",
    "    peft_config = LoraConfig(inference_mode=False, r=rank, lora_alpha=lora_alpha, lora_dropout=0.1, \n",
    "                                target_modules=target_modules)\n",
    "    \n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model\n",
    "\n",
    "model_init2 = partial(get_lora_model, rank=8, target_modules=[\"query\", \"value\", \"key\", \"output.dense\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
