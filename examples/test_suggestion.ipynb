{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmForMaskedLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = EsmForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_sequence = \"MAPLRKTYVLKLYVAGNTPNSVRALKTLNNILEKEFKGVYALKVIDVLKNPQLAEEDKILATPTLAKVLPPPVRRIIGDLSNREKVLIGLDLLYEEIGDQAEDDLGLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(protein_sequence, return_tensors=\"pt\") # it will add a cls and eos tokens, so the lenght is less \n",
    "tokenizer.decode(input_ids[0])\n",
    "sequence_length = input_ids.shape[1] - 2 \n",
    "# List of amino acids\n",
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "masked_input_ids = input_ids.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(protein_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_input_ids[0,56] = tokenizer.mask_token_id\n",
    "with torch.no_grad():\n",
    "    output = model(masked_input_ids).logits\n",
    "    newoutput = model(input_ids).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.1878, -22.0185, -11.5768, -22.0190,   2.1428,   0.3948,  -1.7579,\n",
       "          1.1307,  -1.7544,   2.1297,  -0.8656,  -1.4050,   1.5409,  -2.1582,\n",
       "         -2.3874,  -0.6448,  -1.7216,  -2.0923,   0.6902,   0.4454,  -0.1989,\n",
       "         -1.9539,  -0.7098,  -2.4093,  -7.8731, -12.2290, -12.4519, -12.8954,\n",
       "        -16.0544, -16.4845, -16.5221, -16.6085, -22.0090])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newoutput[0,56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-13.1540, -23.7290, -12.1718, -23.7257,   2.1987,   1.1187,  -0.3541,\n",
       "          1.6377,  -0.7187,  -0.2680,  -0.0645,  -0.5286,   1.7129,  -1.2313,\n",
       "         -1.3465,   0.1527,  -0.5898,  -0.9066,   1.1585,   1.1271,   0.0304,\n",
       "         -0.8827,  -0.3168,  -1.5503,  -7.9917, -11.9826, -12.2444, -12.7819,\n",
       "        -16.1148, -16.4314, -16.4897, -16.5185, -23.7213])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.nn.functional.softmax(output[0, 56], dim=0)\n",
    "log_probabilities = torch.log(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_residue = input_ids[0, 56].item()\n",
    "log_prob_wt = log_probabilities[wt_residue].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 1.39\n",
      "C: -1.28\n",
      "D: -0.96\n",
      "E: 0.00\n",
      "F: 1.43\n",
      "G: -0.09\n",
      "H: -0.61\n",
      "I: 1.98\n",
      "K: 0.42\n",
      "L: 2.47\n",
      "M: 0.30\n",
      "N: -0.64\n",
      "P: -1.08\n",
      "Q: -0.32\n",
      "R: 0.20\n",
      "S: -0.45\n",
      "T: -0.26\n",
      "V: 1.91\n",
      "W: -0.05\n",
      "Y: 1.40\n"
     ]
    }
   ],
   "source": [
    "for i, amino_acid in enumerate(amino_acids):\n",
    "    log_prob_mt = log_probabilities[tokenizer.convert_tokens_to_ids(amino_acid)].item()\n",
    "    u = log_prob_mt - log_prob_wt\n",
    "    print(f\"{amino_acid}: {u:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
