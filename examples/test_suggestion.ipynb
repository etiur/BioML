{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Paper: Efficient evolution of human antibodies from general protein language models\n",
    "https://www-nature-com.sire.ub.edu/articles/s41587-023-01763-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmForMaskedLM, pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = EsmForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_sequence = \"MAPLRKTYVLKLYVAGNTPNSVRALKTLNNILEKEFKGVYALKVIDVLKNPQLAEEDKILATPTLAKVLPPPVRRIIGDLSNREKVLIGLDLLYEEIGDQAEDDLGLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_marginal(positions, input_ids, tokenizer, model):\n",
    "\tall_prob = []\n",
    "\tfor x in positions:\n",
    "\t\tmasked_input_ids = input_ids.clone()\n",
    "\t\tmasked_input_ids[0, x+1] = tokenizer.mask_token_id\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutput = model(masked_input_ids).logits\n",
    "\t\tprobabilities = torch.nn.functional.softmax(output[0, x+1], dim=0)\n",
    "\t\tall_prob.append(probabilities)\n",
    "\treturn all_prob\n",
    "\n",
    "def wild_marginal(positions, input_ids, tokenizer, model):\n",
    "\tall_prob = []\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(input_ids).logits\n",
    "\tfor x in positions:\n",
    "\t\tprobabilities = torch.nn.functional.softmax(output[0, x+1], dim=0)\n",
    "\t\tall_prob.append(probabilities)\n",
    "\treturn all_prob\n",
    "\n",
    "def get_probabilities(protein_sequence, model, tokenizer, positions, strategy=masked_marginal):\n",
    "\t# Encode the protein sequence\n",
    "\tinput_ids = tokenizer.encode(protein_sequence, return_tensors=\"pt\") # it will add a cls and eos tokens, so the lenght is less \n",
    "\t# sequence_length = input_ids.shape[1] - 2 \n",
    "\t# List of amino acids\n",
    "\tamino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\taa_ids = {aa: tokenizer.convert_tokens_to_ids(aa) for aa in amino_acids}\n",
    "\tprob_mt = {}\n",
    "\t# Get the probabilities\t\n",
    "\tall_prob = strategy(positions, input_ids, tokenizer, model)\n",
    "\n",
    "\tfor num, pos in enumerate(positions):\n",
    "\t\twt_residue_id = input_ids[0, pos+1].item()\n",
    "\t\twt_token = tokenizer.convert_ids_to_tokens(wt_residue_id)\n",
    "\t\t# Get the probability of the wild type residue\n",
    "\t\tprob_wt = all_prob[num][wt_residue_id].item()\n",
    "\t\t# Get the probability of the mutant residue\n",
    "\t\tprob_mt[f\"{wt_token}{pos+1}\"] = {f\"{key}\": all_prob[num][value].item()/prob_wt for key, value in aa_ids.items()}\n",
    "\t\t\n",
    "\treturn prob_mt\n",
    "\n",
    "def filter_probabilities_by_alpha(probability, alpha):\n",
    "\t# Filter the probabilities\n",
    "\tfiltered_prob = {}\n",
    "\tfor pos, probs in probability.items():\n",
    "\t\tfiltered_prob[pos] = {aa: prob for aa, prob in probs.items() if prob > alpha}\n",
    "\treturn filtered_prob\n",
    "\n",
    "def filter_probabilities_by_set(probability, aa_set):\n",
    "\t# Filter the probabilities\n",
    "\tfiltered_prob = {}\n",
    "\tfor aa in aa_set:\n",
    "\t\tprint(aa)\n",
    "\t\tfiltered_prob[aa[:2]] = {}\n",
    "\t\tfor mut, probs in probability[aa[:2]].items():\n",
    "\t\t\tif mut == aa[-1]:\n",
    "\t\t\t\tfiltered_prob[aa[:2]][mut] = probs\n",
    "\treturn filtered_prob\n",
    "\n",
    "def return_set(comb_probabilities):\n",
    "\t# Return the set of the probabilities\n",
    "\tprob_set = []\n",
    "\tfor prob in comb_probabilities:\n",
    "\t\tproba = []\n",
    "\t\tfor key, value in prob.items():\n",
    "\t\t\tproba.extend([f\"{key}{k}\" for k in value.keys()])\n",
    "\t\tprob_set.append(proba)\n",
    "\tprob = set(prob_set[0]).intersection(*prob_set[1:])\n",
    "\treturn prob\n",
    "\n",
    "def filter_by_k(probabilities, k):\n",
    "\t# Filter the probability based on how many models agree\n",
    "\tsets = list(itertools.combinations(probabilities, k))\n",
    "\tall_sets = [return_set(comb_probabilities) for comb_probabilities in sets]\n",
    "\tall_sets = all_sets[0].union(*all_sets[1:])\n",
    "\tnew_probabilities = [filter_probabilities_by_set(prob, all_sets) for prob in probabilities]\n",
    "\treturn new_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A2'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(return_set([filt_prob, {\"A2\":{\"K\": 1.2832646359631252}}]))[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A2': {'K': 1.2832646359631252}}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_probabilities_by_set(filt_prob, {\"A2K\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A2': {'K': 1.2832646359631252,\n",
       "  'S': 1.3499720299565006,\n",
       "  'T': 1.134130875488756},\n",
       " 'P3': {'A': 1.343672702699494,\n",
       "  'D': 1.8337239835837849,\n",
       "  'E': 2.8642443382922336,\n",
       "  'I': 1.1901972841480097,\n",
       "  'K': 2.427308546748088,\n",
       "  'L': 1.0872151831521402,\n",
       "  'N': 1.5681692107578713,\n",
       "  'S': 2.114671266742389,\n",
       "  'T': 1.9366846474616473,\n",
       "  'V': 1.076543208655055},\n",
       " 'L4': {'A': 1.9119232256504048,\n",
       "  'D': 1.2088964148834553,\n",
       "  'E': 2.0831391382160014,\n",
       "  'K': 2.863379731175463,\n",
       "  'P': 2.172903160342404,\n",
       "  'S': 2.008179354647393,\n",
       "  'T': 1.9535540455935805,\n",
       "  'V': 1.2937871824880731},\n",
       " 'R5': {'A': 1.9734289794415862,\n",
       "  'D': 2.3923876554310173,\n",
       "  'E': 3.2719752648186367,\n",
       "  'G': 1.5413116950659302,\n",
       "  'K': 4.1936655562648655,\n",
       "  'L': 1.2357690368349021,\n",
       "  'N': 2.0560529223890502,\n",
       "  'P': 4.32327157748328,\n",
       "  'Q': 1.3518319357028772,\n",
       "  'S': 3.3164105830282047,\n",
       "  'T': 2.7459009490799704,\n",
       "  'V': 1.2904952017755453},\n",
       " 'K6': {},\n",
       " 'T7': {'D': 1.9819635683529342,\n",
       "  'E': 2.5870204718903906,\n",
       "  'G': 1.5992280932005885,\n",
       "  'K': 2.4021768534106753,\n",
       "  'N': 1.138612820071747,\n",
       "  'P': 1.8504205553747415,\n",
       "  'S': 1.5127189125304223},\n",
       " 'Y8': {'A': 2.8379098337878763,\n",
       "  'D': 5.095696006321497,\n",
       "  'E': 8.162321311104352,\n",
       "  'G': 4.960533083275821,\n",
       "  'H': 1.1887796964347606,\n",
       "  'I': 1.3500022482945802,\n",
       "  'K': 10.923613560096156,\n",
       "  'L': 1.8035899959480175,\n",
       "  'N': 3.5944026053944924,\n",
       "  'P': 8.633595684891157,\n",
       "  'Q': 2.80379587910339,\n",
       "  'R': 3.700656754634771,\n",
       "  'S': 4.190033436434902,\n",
       "  'T': 3.9990936088816227,\n",
       "  'V': 2.2709306120716746},\n",
       " 'V9': {'D': 1.861931055799138,\n",
       "  'E': 2.2612640245403584,\n",
       "  'K': 2.465826732439633,\n",
       "  'N': 1.2125318131778777,\n",
       "  'P': 2.032842872311867,\n",
       "  'S': 1.3684578416924575,\n",
       "  'T': 1.9556036290562684},\n",
       " 'L10': {'V': 1.0606003192638893},\n",
       " 'K11': {'D': 1.2279090401732062,\n",
       "  'E': 2.135774055416655,\n",
       "  'T': 1.4218452653742737}}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = get_probabilities(protein_sequence, model, tokenizer, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "filt_prob = filter_probabilities_by_alpha(prob, 1)\n",
    "filt_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(protein_sequence, return_tensors=\"pt\") # it will add a cls and eos tokens, so the lenght is less \n",
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequence_length = input_ids.shape[1] - 2 \n",
    "# List of amino acids\n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "aa_ids = {aa: tokenizer.convert_tokens_to_ids(aa) for aa in amino_acids}\n",
    "masked_input_ids = input_ids.clone()\n",
    "masked_input_ids[0,56] = tokenizer.mask_token_id\n",
    "with torch.no_grad():\n",
    "    output = model(masked_input_ids).logits\n",
    "    newoutput = model(input_ids).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prob = []\n",
    "for x in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "\tmasked_input_ids = input_ids.clone()\n",
    "\tmasked_input_ids[0, x+1] = tokenizer.mask_token_id\n",
    "\twith torch.no_grad():\n",
    "\t\toutput = model(masked_input_ids).logits\n",
    "\twt_residue_id = input_ids[0, x+1].item()\n",
    "\twt_token = tokenizer.convert_ids_to_tokens(wt_residue_id)\n",
    "\t# Get the probability of the wild type residue\n",
    "\tprobabilities = torch.nn.functional.softmax(output[0, x+1], dim=-1)\n",
    "\tall_prob.append(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2098e-07, 5.5431e-12, 5.2519e-07, 5.5082e-12, 4.9137e-02, 9.3152e-02,\n",
       "        2.7678e-02, 4.3878e-02, 1.2575e-01, 7.7442e-02, 3.1851e-02, 1.0565e-01,\n",
       "        5.8779e-02, 5.1997e-02, 6.2361e-02, 1.1954e-01, 3.1374e-02, 7.0313e-02,\n",
       "        1.3865e-02, 1.0678e-02, 1.0953e-02, 1.1653e-02, 1.4777e-03, 2.3821e-03,\n",
       "        8.9663e-05, 2.6679e-07, 1.8436e-07, 9.9049e-08, 2.9584e-09, 2.1299e-09,\n",
       "        2.2080e-09, 2.2518e-09, 5.5910e-12])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(all_prob)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-16.7804, -27.3554, -15.7982, -27.3520,  -1.4277,  -2.5076,  -3.9805,\n",
       "         -1.9887,  -4.3450,  -3.8944,  -3.6909,  -4.1550,  -1.9134,  -4.8577,\n",
       "         -4.9729,  -3.4737,  -4.2161,  -4.5330,  -2.4678,  -2.4993,  -3.5960,\n",
       "         -4.5091,  -3.9432,  -5.1766, -11.6180, -15.6090, -15.8708, -16.4083,\n",
       "        -19.7412, -20.0578, -20.1161, -20.1449, -27.3477])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = torch.nn.functional.softmax(output[0, 56], dim=0)\n",
    "log_probabilities = torch.log(probabilities)\n",
    "log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_residue = input_ids[0, 56].item()\n",
    "\n",
    "log_prob_wt = log_probabilities[wt_residue].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 1.39\n",
      "C: -1.28\n",
      "D: -0.96\n",
      "E: 0.00\n",
      "F: 1.43\n",
      "G: -0.09\n",
      "H: -0.61\n",
      "I: 1.98\n",
      "K: 0.42\n",
      "L: 2.47\n",
      "M: 0.30\n",
      "N: -0.64\n",
      "P: -1.08\n",
      "Q: -0.32\n",
      "R: 0.20\n",
      "S: -0.45\n",
      "T: -0.26\n",
      "V: 1.91\n",
      "W: -0.05\n",
      "Y: 1.40\n"
     ]
    }
   ],
   "source": [
    "for i, amino_acid in enumerate(amino_acids):\n",
    "    log_prob_mt = log_probabilities[tokenizer.convert_tokens_to_ids(amino_acid)].item()\n",
    "    u = log_prob_mt - log_prob_wt\n",
    "    print(f\"{amino_acid}: {u:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E56A': 4.001879542035948,\n",
       " 'E56C': 0.2774215940895632,\n",
       " 'E56D': 0.38165176240465715,\n",
       " 'E56E': 1.0,\n",
       " 'E56F': 4.164444006026979,\n",
       " 'E56G': 0.9174956996554051,\n",
       " 'E56H': 0.5408050497639408,\n",
       " 'E56I': 7.24976954106049,\n",
       " 'E56K': 1.5230791107844535,\n",
       " 'E56L': 11.783465044635921,\n",
       " 'E56M': 1.3477541668824693,\n",
       " 'E56N': 0.5280566944547288,\n",
       " 'E56P': 0.34012259939748507,\n",
       " 'E56Q': 0.7249081595733019,\n",
       " 'E56R': 1.2257103964296387,\n",
       " 'E56S': 0.6372239090923898,\n",
       " 'E56T': 0.770610221597457,\n",
       " 'E56V': 6.724243731397887,\n",
       " 'E56W': 0.9524152847213364,\n",
       " 'E56Y': 4.035606249303408}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_wt = probabilities[wt_residue].item()\n",
    "# Get the probability of the mutant residue\n",
    "prob_mt = {f\"E56{key}\": probabilities[value].item()/prob_wt for key, value in aa_ids.items()}\n",
    "prob_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.625357189342083"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_mt[\"E56L\"] / prob_mt[\"E56I\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(task=\"fill-mask\", model=model_name, tokenizer=model_name, top_k=20)\n",
    "\n",
    "def use_pipe_marginal(pipe, sequence, positions, tokenizer):\n",
    "\tseq = []\n",
    "\tfor pos in positions:\n",
    "\t\tsequence = sequence[:pos] + tokenizer.mask_token + sequence[pos+1:]\n",
    "\t\tseq.append(sequence)\n",
    "\treturn pipe(seq)\n",
    "\n",
    "\n",
    "def parse_pipe_output(output, sequence, positions):\n",
    "\tall_proba = {}\n",
    "\tfor num, pos in enumerate(positions):\n",
    "\t\twild = sequence[pos]\n",
    "\t\tall_proba[f\"{wild}{pos}\"] = {x[\"token_str\"]: x[\"score\"] for x in output[num]}\n",
    "\t\tall_proba[f\"{wild}{pos}\"] = {k: v / all_proba[f\"{wild}{pos}\"][wild] for k, v in all_proba[f\"{wild}{pos}\"].items()}\n",
    "\treturn pd.DataFrame(all_proba).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025572</td>\n",
       "      <td>0.558195</td>\n",
       "      <td>0.831349</td>\n",
       "      <td>0.148847</td>\n",
       "      <td>0.297127</td>\n",
       "      <td>0.125095</td>\n",
       "      <td>0.630997</td>\n",
       "      <td>1.283265</td>\n",
       "      <td>0.527495</td>\n",
       "      <td>0.117577</td>\n",
       "      <td>0.754814</td>\n",
       "      <td>0.669457</td>\n",
       "      <td>0.336804</td>\n",
       "      <td>0.341929</td>\n",
       "      <td>1.349972</td>\n",
       "      <td>1.134131</td>\n",
       "      <td>0.471038</td>\n",
       "      <td>0.015863</td>\n",
       "      <td>0.114632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3</th>\n",
       "      <td>1.343673</td>\n",
       "      <td>0.057835</td>\n",
       "      <td>1.833724</td>\n",
       "      <td>2.864244</td>\n",
       "      <td>0.384301</td>\n",
       "      <td>0.914949</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>1.190197</td>\n",
       "      <td>2.427309</td>\n",
       "      <td>1.087215</td>\n",
       "      <td>0.193616</td>\n",
       "      <td>1.568169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777088</td>\n",
       "      <td>0.730884</td>\n",
       "      <td>2.114671</td>\n",
       "      <td>1.936685</td>\n",
       "      <td>1.076543</td>\n",
       "      <td>0.049764</td>\n",
       "      <td>0.326103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L4</th>\n",
       "      <td>1.911923</td>\n",
       "      <td>0.046710</td>\n",
       "      <td>1.208896</td>\n",
       "      <td>2.083139</td>\n",
       "      <td>0.208951</td>\n",
       "      <td>0.732715</td>\n",
       "      <td>0.219586</td>\n",
       "      <td>0.899000</td>\n",
       "      <td>2.863380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117386</td>\n",
       "      <td>0.897115</td>\n",
       "      <td>2.172903</td>\n",
       "      <td>0.915103</td>\n",
       "      <td>0.794621</td>\n",
       "      <td>2.008179</td>\n",
       "      <td>1.953554</td>\n",
       "      <td>1.293787</td>\n",
       "      <td>0.032136</td>\n",
       "      <td>0.188638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R5</th>\n",
       "      <td>1.973429</td>\n",
       "      <td>0.095662</td>\n",
       "      <td>2.392388</td>\n",
       "      <td>3.271975</td>\n",
       "      <td>0.326470</td>\n",
       "      <td>1.541312</td>\n",
       "      <td>0.364618</td>\n",
       "      <td>0.966675</td>\n",
       "      <td>4.193666</td>\n",
       "      <td>1.235769</td>\n",
       "      <td>0.193045</td>\n",
       "      <td>2.056053</td>\n",
       "      <td>4.323272</td>\n",
       "      <td>1.351832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.316411</td>\n",
       "      <td>2.745901</td>\n",
       "      <td>1.290495</td>\n",
       "      <td>0.044551</td>\n",
       "      <td>0.291857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K6</th>\n",
       "      <td>0.276130</td>\n",
       "      <td>0.030226</td>\n",
       "      <td>0.507187</td>\n",
       "      <td>0.579249</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.641203</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.119002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173978</td>\n",
       "      <td>0.045722</td>\n",
       "      <td>0.484264</td>\n",
       "      <td>0.732273</td>\n",
       "      <td>0.255497</td>\n",
       "      <td>0.316409</td>\n",
       "      <td>0.588060</td>\n",
       "      <td>0.392850</td>\n",
       "      <td>0.151816</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.076425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T7</th>\n",
       "      <td>0.819319</td>\n",
       "      <td>0.061215</td>\n",
       "      <td>1.981964</td>\n",
       "      <td>2.587020</td>\n",
       "      <td>0.171343</td>\n",
       "      <td>1.599228</td>\n",
       "      <td>0.271671</td>\n",
       "      <td>0.415586</td>\n",
       "      <td>2.402177</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.107403</td>\n",
       "      <td>1.138613</td>\n",
       "      <td>1.850421</td>\n",
       "      <td>0.620420</td>\n",
       "      <td>0.794016</td>\n",
       "      <td>1.512719</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601088</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.223367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y8</th>\n",
       "      <td>2.837910</td>\n",
       "      <td>0.146315</td>\n",
       "      <td>5.095696</td>\n",
       "      <td>8.162321</td>\n",
       "      <td>0.599036</td>\n",
       "      <td>4.960533</td>\n",
       "      <td>1.188780</td>\n",
       "      <td>1.350002</td>\n",
       "      <td>10.923614</td>\n",
       "      <td>1.803590</td>\n",
       "      <td>0.455732</td>\n",
       "      <td>3.594403</td>\n",
       "      <td>8.633596</td>\n",
       "      <td>2.803796</td>\n",
       "      <td>3.700657</td>\n",
       "      <td>4.190033</td>\n",
       "      <td>3.999094</td>\n",
       "      <td>2.270931</td>\n",
       "      <td>0.094145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.783819</td>\n",
       "      <td>0.054291</td>\n",
       "      <td>1.861931</td>\n",
       "      <td>2.261264</td>\n",
       "      <td>0.269974</td>\n",
       "      <td>0.834610</td>\n",
       "      <td>0.400744</td>\n",
       "      <td>0.695419</td>\n",
       "      <td>2.465827</td>\n",
       "      <td>0.901744</td>\n",
       "      <td>0.134310</td>\n",
       "      <td>1.212532</td>\n",
       "      <td>2.032843</td>\n",
       "      <td>0.808421</td>\n",
       "      <td>0.995437</td>\n",
       "      <td>1.368458</td>\n",
       "      <td>1.955604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056016</td>\n",
       "      <td>0.372498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L10</th>\n",
       "      <td>0.292952</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.059589</td>\n",
       "      <td>0.082817</td>\n",
       "      <td>0.258523</td>\n",
       "      <td>0.148658</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.820341</td>\n",
       "      <td>0.107850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101818</td>\n",
       "      <td>0.053985</td>\n",
       "      <td>0.214230</td>\n",
       "      <td>0.035702</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>0.139872</td>\n",
       "      <td>1.060600</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>0.128020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K11</th>\n",
       "      <td>0.686631</td>\n",
       "      <td>0.093666</td>\n",
       "      <td>1.227909</td>\n",
       "      <td>2.135774</td>\n",
       "      <td>0.138714</td>\n",
       "      <td>0.770501</td>\n",
       "      <td>0.386378</td>\n",
       "      <td>0.418194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459316</td>\n",
       "      <td>0.087919</td>\n",
       "      <td>0.490002</td>\n",
       "      <td>0.130282</td>\n",
       "      <td>0.345678</td>\n",
       "      <td>0.529347</td>\n",
       "      <td>0.699894</td>\n",
       "      <td>1.421845</td>\n",
       "      <td>0.921015</td>\n",
       "      <td>0.035992</td>\n",
       "      <td>0.310612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         C         D         E         F         G         H  \\\n",
       "A2   1.000000  0.025572  0.558195  0.831349  0.148847  0.297127  0.125095   \n",
       "P3   1.343673  0.057835  1.833724  2.864244  0.384301  0.914949  0.254400   \n",
       "L4   1.911923  0.046710  1.208896  2.083139  0.208951  0.732715  0.219586   \n",
       "R5   1.973429  0.095662  2.392388  3.271975  0.326470  1.541312  0.364618   \n",
       "K6   0.276130  0.030226  0.507187  0.579249  0.063158  0.641203  0.093900   \n",
       "T7   0.819319  0.061215  1.981964  2.587020  0.171343  1.599228  0.271671   \n",
       "Y8   2.837910  0.146315  5.095696  8.162321  0.599036  4.960533  1.188780   \n",
       "V9   0.783819  0.054291  1.861931  2.261264  0.269974  0.834610  0.400744   \n",
       "L10  0.292952  0.040045  0.059589  0.082817  0.258523  0.148658  0.027128   \n",
       "K11  0.686631  0.093666  1.227909  2.135774  0.138714  0.770501  0.386378   \n",
       "\n",
       "            I          K         L         M         N         P         Q  \\\n",
       "A2   0.630997   1.283265  0.527495  0.117577  0.754814  0.669457  0.336804   \n",
       "P3   1.190197   2.427309  1.087215  0.193616  1.568169  1.000000  0.777088   \n",
       "L4   0.899000   2.863380  1.000000  0.117386  0.897115  2.172903  0.915103   \n",
       "R5   0.966675   4.193666  1.235769  0.193045  2.056053  4.323272  1.351832   \n",
       "K6   0.119002   1.000000  0.173978  0.045722  0.484264  0.732273  0.255497   \n",
       "T7   0.415586   2.402177  0.486920  0.107403  1.138613  1.850421  0.620420   \n",
       "Y8   1.350002  10.923614  1.803590  0.455732  3.594403  8.633596  2.803796   \n",
       "V9   0.695419   2.465827  0.901744  0.134310  1.212532  2.032843  0.808421   \n",
       "L10  0.820341   0.107850  1.000000  0.101818  0.053985  0.214230  0.035702   \n",
       "K11  0.418194   1.000000  0.459316  0.087919  0.490002  0.130282  0.345678   \n",
       "\n",
       "            R         S         T         V         W         Y  \n",
       "A2   0.341929  1.349972  1.134131  0.471038  0.015863  0.114632  \n",
       "P3   0.730884  2.114671  1.936685  1.076543  0.049764  0.326103  \n",
       "L4   0.794621  2.008179  1.953554  1.293787  0.032136  0.188638  \n",
       "R5   1.000000  3.316411  2.745901  1.290495  0.044551  0.291857  \n",
       "K6   0.316409  0.588060  0.392850  0.151816  0.012046  0.076425  \n",
       "T7   0.794016  1.512719  1.000000  0.601088  0.026687  0.223367  \n",
       "Y8   3.700657  4.190033  3.999094  2.270931  0.094145  1.000000  \n",
       "V9   0.995437  1.368458  1.955604  1.000000  0.056016  0.372498  \n",
       "L10  0.057471  0.073047  0.139872  1.060600  0.025686  0.128020  \n",
       "K11  0.529347  0.699894  1.421845  0.921015  0.035992  0.310612  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probabilities(protein_sequence, model, tokenizer, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>A</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>I</th>\n",
       "      <th>D</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>R</th>\n",
       "      <th>Q</th>\n",
       "      <th>G</th>\n",
       "      <th>F</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>Y</th>\n",
       "      <th>C</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1</th>\n",
       "      <td>1.349972</td>\n",
       "      <td>1.283265</td>\n",
       "      <td>1.134131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831349</td>\n",
       "      <td>0.754814</td>\n",
       "      <td>0.669457</td>\n",
       "      <td>0.630997</td>\n",
       "      <td>0.558195</td>\n",
       "      <td>0.527495</td>\n",
       "      <td>0.471038</td>\n",
       "      <td>0.341929</td>\n",
       "      <td>0.336804</td>\n",
       "      <td>0.297127</td>\n",
       "      <td>0.148847</td>\n",
       "      <td>0.125095</td>\n",
       "      <td>0.117577</td>\n",
       "      <td>0.114632</td>\n",
       "      <td>0.025572</td>\n",
       "      <td>0.015863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>1.565557</td>\n",
       "      <td>1.799515</td>\n",
       "      <td>1.286391</td>\n",
       "      <td>0.988343</td>\n",
       "      <td>1.253368</td>\n",
       "      <td>1.099248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.043457</td>\n",
       "      <td>0.891353</td>\n",
       "      <td>1.304214</td>\n",
       "      <td>0.764856</td>\n",
       "      <td>0.858806</td>\n",
       "      <td>0.642436</td>\n",
       "      <td>0.888907</td>\n",
       "      <td>0.555891</td>\n",
       "      <td>0.334455</td>\n",
       "      <td>0.173488</td>\n",
       "      <td>0.455629</td>\n",
       "      <td>0.209028</td>\n",
       "      <td>0.141089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3</th>\n",
       "      <td>1.200384</td>\n",
       "      <td>1.379770</td>\n",
       "      <td>0.986334</td>\n",
       "      <td>0.757808</td>\n",
       "      <td>0.961014</td>\n",
       "      <td>0.842844</td>\n",
       "      <td>0.766746</td>\n",
       "      <td>0.800066</td>\n",
       "      <td>0.683441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586450</td>\n",
       "      <td>0.658485</td>\n",
       "      <td>0.492585</td>\n",
       "      <td>0.681566</td>\n",
       "      <td>0.426227</td>\n",
       "      <td>0.256442</td>\n",
       "      <td>0.133021</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>0.160271</td>\n",
       "      <td>0.108179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R4</th>\n",
       "      <td>1.822947</td>\n",
       "      <td>2.095370</td>\n",
       "      <td>1.497883</td>\n",
       "      <td>1.150835</td>\n",
       "      <td>1.459431</td>\n",
       "      <td>1.279974</td>\n",
       "      <td>1.164408</td>\n",
       "      <td>1.215010</td>\n",
       "      <td>1.037898</td>\n",
       "      <td>1.518637</td>\n",
       "      <td>0.890605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748057</td>\n",
       "      <td>1.035051</td>\n",
       "      <td>0.647284</td>\n",
       "      <td>0.389442</td>\n",
       "      <td>0.202011</td>\n",
       "      <td>0.530538</td>\n",
       "      <td>0.243394</td>\n",
       "      <td>0.164285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K5</th>\n",
       "      <td>0.869988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714854</td>\n",
       "      <td>0.549228</td>\n",
       "      <td>0.696503</td>\n",
       "      <td>0.610858</td>\n",
       "      <td>0.555705</td>\n",
       "      <td>0.579855</td>\n",
       "      <td>0.495330</td>\n",
       "      <td>0.724758</td>\n",
       "      <td>0.425035</td>\n",
       "      <td>0.477243</td>\n",
       "      <td>0.357005</td>\n",
       "      <td>0.493970</td>\n",
       "      <td>0.308912</td>\n",
       "      <td>0.185858</td>\n",
       "      <td>0.096408</td>\n",
       "      <td>0.253196</td>\n",
       "      <td>0.116158</td>\n",
       "      <td>0.078404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T6</th>\n",
       "      <td>1.217015</td>\n",
       "      <td>1.398887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768307</td>\n",
       "      <td>0.974329</td>\n",
       "      <td>0.854522</td>\n",
       "      <td>0.777369</td>\n",
       "      <td>0.811151</td>\n",
       "      <td>0.692910</td>\n",
       "      <td>1.013855</td>\n",
       "      <td>0.594576</td>\n",
       "      <td>0.667609</td>\n",
       "      <td>0.499410</td>\n",
       "      <td>0.691009</td>\n",
       "      <td>0.432132</td>\n",
       "      <td>0.259995</td>\n",
       "      <td>0.134864</td>\n",
       "      <td>0.354192</td>\n",
       "      <td>0.162492</td>\n",
       "      <td>0.109678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y7</th>\n",
       "      <td>3.436032</td>\n",
       "      <td>3.949515</td>\n",
       "      <td>2.823327</td>\n",
       "      <td>2.169183</td>\n",
       "      <td>2.750849</td>\n",
       "      <td>2.412593</td>\n",
       "      <td>2.194766</td>\n",
       "      <td>2.290144</td>\n",
       "      <td>1.956311</td>\n",
       "      <td>2.862444</td>\n",
       "      <td>1.678681</td>\n",
       "      <td>1.884877</td>\n",
       "      <td>1.409996</td>\n",
       "      <td>1.950943</td>\n",
       "      <td>1.220051</td>\n",
       "      <td>0.734051</td>\n",
       "      <td>0.380766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458767</td>\n",
       "      <td>0.309657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>2.046864</td>\n",
       "      <td>2.352749</td>\n",
       "      <td>1.681872</td>\n",
       "      <td>1.292195</td>\n",
       "      <td>1.638697</td>\n",
       "      <td>1.437196</td>\n",
       "      <td>1.307435</td>\n",
       "      <td>1.364252</td>\n",
       "      <td>1.165386</td>\n",
       "      <td>1.705174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.122832</td>\n",
       "      <td>0.839943</td>\n",
       "      <td>1.162188</td>\n",
       "      <td>0.726791</td>\n",
       "      <td>0.437278</td>\n",
       "      <td>0.226824</td>\n",
       "      <td>0.595706</td>\n",
       "      <td>0.273290</td>\n",
       "      <td>0.184465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L9</th>\n",
       "      <td>1.200384</td>\n",
       "      <td>1.379770</td>\n",
       "      <td>0.986334</td>\n",
       "      <td>0.757808</td>\n",
       "      <td>0.961014</td>\n",
       "      <td>0.842844</td>\n",
       "      <td>0.766746</td>\n",
       "      <td>0.800066</td>\n",
       "      <td>0.683441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586450</td>\n",
       "      <td>0.658485</td>\n",
       "      <td>0.492585</td>\n",
       "      <td>0.681566</td>\n",
       "      <td>0.426227</td>\n",
       "      <td>0.256442</td>\n",
       "      <td>0.133021</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>0.160271</td>\n",
       "      <td>0.108179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K10</th>\n",
       "      <td>0.869988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714854</td>\n",
       "      <td>0.549228</td>\n",
       "      <td>0.696503</td>\n",
       "      <td>0.610858</td>\n",
       "      <td>0.555705</td>\n",
       "      <td>0.579855</td>\n",
       "      <td>0.495330</td>\n",
       "      <td>0.724758</td>\n",
       "      <td>0.425035</td>\n",
       "      <td>0.477243</td>\n",
       "      <td>0.357005</td>\n",
       "      <td>0.493970</td>\n",
       "      <td>0.308912</td>\n",
       "      <td>0.185858</td>\n",
       "      <td>0.096408</td>\n",
       "      <td>0.253196</td>\n",
       "      <td>0.116158</td>\n",
       "      <td>0.078404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            S         K         T         A         E         N         P  \\\n",
       "A1   1.349972  1.283265  1.134131  1.000000  0.831349  0.754814  0.669457   \n",
       "P2   1.565557  1.799515  1.286391  0.988343  1.253368  1.099248  1.000000   \n",
       "L3   1.200384  1.379770  0.986334  0.757808  0.961014  0.842844  0.766746   \n",
       "R4   1.822947  2.095370  1.497883  1.150835  1.459431  1.279974  1.164408   \n",
       "K5   0.869988  1.000000  0.714854  0.549228  0.696503  0.610858  0.555705   \n",
       "T6   1.217015  1.398887  1.000000  0.768307  0.974329  0.854522  0.777369   \n",
       "Y7   3.436032  3.949515  2.823327  2.169183  2.750849  2.412593  2.194766   \n",
       "V8   2.046864  2.352749  1.681872  1.292195  1.638697  1.437196  1.307435   \n",
       "L9   1.200384  1.379770  0.986334  0.757808  0.961014  0.842844  0.766746   \n",
       "K10  0.869988  1.000000  0.714854  0.549228  0.696503  0.610858  0.555705   \n",
       "\n",
       "            I         D         L         V         R         Q         G  \\\n",
       "A1   0.630997  0.558195  0.527495  0.471038  0.341929  0.336804  0.297127   \n",
       "P2   1.043457  0.891353  1.304214  0.764856  0.858806  0.642436  0.888907   \n",
       "L3   0.800066  0.683441  1.000000  0.586450  0.658485  0.492585  0.681566   \n",
       "R4   1.215010  1.037898  1.518637  0.890605  1.000000  0.748057  1.035051   \n",
       "K5   0.579855  0.495330  0.724758  0.425035  0.477243  0.357005  0.493970   \n",
       "T6   0.811151  0.692910  1.013855  0.594576  0.667609  0.499410  0.691009   \n",
       "Y7   2.290144  1.956311  2.862444  1.678681  1.884877  1.409996  1.950943   \n",
       "V8   1.364252  1.165386  1.705174  1.000000  1.122832  0.839943  1.162188   \n",
       "L9   0.800066  0.683441  1.000000  0.586450  0.658485  0.492585  0.681566   \n",
       "K10  0.579855  0.495330  0.724758  0.425035  0.477243  0.357005  0.493970   \n",
       "\n",
       "            F         H         M         Y         C         W  \n",
       "A1   0.148847  0.125095  0.117577  0.114632  0.025572  0.015863  \n",
       "P2   0.555891  0.334455  0.173488  0.455629  0.209028  0.141089  \n",
       "L3   0.426227  0.256442  0.133021  0.349352  0.160271  0.108179  \n",
       "R4   0.647284  0.389442  0.202011  0.530538  0.243394  0.164285  \n",
       "K5   0.308912  0.185858  0.096408  0.253196  0.116158  0.078404  \n",
       "T6   0.432132  0.259995  0.134864  0.354192  0.162492  0.109678  \n",
       "Y7   1.220051  0.734051  0.380766  1.000000  0.458767  0.309657  \n",
       "V8   0.726791  0.437278  0.226824  0.595706  0.273290  0.184465  \n",
       "L9   0.426227  0.256442  0.133021  0.349352  0.160271  0.108179  \n",
       "K10  0.308912  0.185858  0.096408  0.253196  0.116158  0.078404  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use = use_pipe(pipe, protein_sequence, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], tokenizer)\n",
    "parse_pipe_output(use, protein_sequence, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2398565262556076,\n",
       " 'token': 4,\n",
       " 'token_str': 'L',\n",
       " 'sequence': 'M A P L R K T Y V L K L Y V A G N T P N S V R A L K T L N N I L E K E F K G V Y A L K V I D V L K N P Q L A E L D K I L A T P T L A K V L P P P V R R I I G D L S N R E K V L I G L D L L Y E E I G D Q A E D D L G L E'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pipe(protein_sequence[:55] + tokenizer.mask_token + protein_sequence[56:], top_k=20)\n",
    "res[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
